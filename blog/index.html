<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Blog</title>
  <meta name="description" content="A Jekyll theme based on tufte-css">

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <link rel="stylesheet" type="text/css" href="/tufte-css-jekyll/css/tufte.css">
  <link rel="stylesheet" type="text/css" href="/tufte-css-jekyll/css/latex.css">
  <!-- <link rel="stylesheet" type="text/css" href="/tufte-css-jekyll/css/print.css" media="print"> -->

  <link rel="canonical" href="/tufte-css-jekyll/blog/">

  <link rel="alternate" type="application/rss+xml" title="tufte-css-jekyll" href="/tufte-css-jekyll/feed.xml" />
</head>

  <body class="full-width">
    <!--- Header and nav template site-wide -->
<header>
	
		<h1 class="header-title"><a href="/tufte-css-jekyll/">tufte-css-jekyll</a></h1>
		
			<h2 class="header-subtitle">A Jekyll theme based on tufte-css</h2>
		
	

    <nav class="group">
	
	
		
  	
		
  	
		
  	
		
		    
		      <a href="/tufte-css-jekyll/">About</a>
		    
	    
  	
		
		    
		      <a class="active" href="/tufte-css-jekyll/blog/" class="active">Blog</a>
		    
	    
  	
		
		    
		      <a href="/tufte-css-jekyll/page/">Tufte CSS</a>
		    
	    
  	
	</nav>
</header>
    <article>
        <h1 class="content-listing-header sans">Articles</h1>
  <ul class="content-listing ">
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/optimisation/2021/10/10/gradient-descent.html"><h2 class="larger">The ins and outs of Gradient Descent</h2></a>
          <br><span class="smaller">October 10, 2021</span>  <br/>
          <div><p>Gradient Descent is the simplest learning algorithm.</p>

<p>Suppose you have a set of observations of some process you wanted to model, for example the size of a house labelled as $ x_i \in \mathrm{R}^n $, and the house price labeleld as $ y_i \in \mathrm{R} $, $ i = 1 \ldots m$ (i.e. you have $m$ examples). One good choice for a model is linear:</p>

\[\hat{y}\left(x\right) = Ax + b\]

<p>The goal is to find some suitable $ A \in \mathcal{R}^n $ and $ b \in \mathcal{R} $, to model this process corectly. An example is shown below (the data is taken from the Coursera Machine Learning class).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span> 
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="p">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="sh">'</span><span class="s">retina</span><span class="sh">'</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">([</span><span class="sh">'</span><span class="s">seaborn-colorblind</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">seaborn-darkgrid</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x109cba630&gt;
</code></pre></div></div>

<p><img src="2021-02-01-Gradietnt-Descent_files/2021-02-01-Gradietnt-Descent_2_1.png" alt="png" /></p>

<p>We’ll generate some data that we’ll use for the rest of this post:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">2.25</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">1.5</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Generate n data points approximating given line.
    m, b: line slope and intercept.
    stddev: standard deviation of added error.
    Returns pair x, y: arrays of length n.
    </span><span class="sh">"""</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">m</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">stddev</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.collections.PathCollection at 0x10ee65438&gt;
</code></pre></div></div>

<p><img src="2021-02-01-Gradietnt-Descent_files/2021-02-01-Gradietnt-Descent_5_1.png" alt="png" /></p>

<p>For convenience, let’s define $\Theta = [A: b]$ be a $ (n+1) \times 1 $ vector, let $ X = [x_1: \ldots : x_m :1] \in \mathrm{R}^{(n+1) \times m} $, and let $Y = [y_1: \ldots : y_m :1]$ (i.e. we expanded both to include the intercept, and we concatenate all the examples into a single matrix of x’s and y’s respectively). Now out hypothesis can be written as $ \hat{Y} = \Theta^T X $</p>

<p>Say you also had good reason to believe that the best reconstruction of $ x $ you could possilby hope to achieve was to minimise the following (mean squared) error measure:</p>

\[J\left(\Theta\right) = \frac{1}{n} \lVert \hat{Y} - Y\rVert_2^2\]

<p>A function to compute the cost is below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">MSE</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Function to compute MSE between true values and estimate
    
    y: true values
    yhat: estimate
    </span><span class="sh">"""</span>
    <span class="nf">assert</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">yhat</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)).</span><span class="nf">mean</span><span class="p">()</span>
</code></pre></div></div>

<p>We could also seek to minimise the least absolute deviations of our predictions from the data:</p>

\[J\left(\Theta\right)  = \frac{1}{n} \lVert \hat{Y} - Y\rVert_1\]

<p>a function to do this is included below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">MAE</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Function to compute LAE between true values and estimate
    
    y: true values
    yhat: estimate
    </span><span class="sh">"""</span>
    <span class="nf">assert</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">yhat</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">absolute</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
</code></pre></div></div>

<p>There are a couple of ways you could find such an $ \hat{Y} $, given a cost function. The most straigtforward is to start with some initital value, and then move in the direction of the negative gradient of the cost funtion:</p>

\[\Theta_{k+1} = \Theta_{k} - \alpha\nabla_{\Theta} J\left(\Theta\right)\]

<p>with $ \Theta_0 = 0 $. Here. $\alpha$ is the learning rate - a tuneable parameter.</p>

<p>The following function does exactly this, using autograd to avoid mathematically computing the gradients.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">num_iters</span><span class="o">=</span><span class="mi">250</span><span class="p">):</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">theta</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span>
    <span class="k">yield</span> <span class="n">theta</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">yhat</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">theta</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span>
        <span class="n">yhatt</span> <span class="o">=</span> <span class="n">yhat</span><span class="p">.</span><span class="n">T</span>
        <span class="n">nabla</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">yhatt</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="nf">assert</span><span class="p">(</span><span class="n">nabla</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">theta</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">theta</span> <span class="o">+=</span>  <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">learning_rate</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">nabla</span>
        <span class="k">yield</span> <span class="n">theta</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">yhat</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">ones</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">thetas</span> <span class="o">=</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">MSE</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final</span> <span class="o">=</span> <span class="p">[(</span><span class="n">t</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span><span class="n">c</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>
<span class="n">costs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">final</span><span class="p">]</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">final</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x10eedc898&gt;]
</code></pre></div></div>

<p><img src="2021-02-01-Gradietnt-Descent_files/2021-02-01-Gradietnt-Descent_14_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">theta</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[ 2.27769915],
       [ 5.90213934]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="sh">"</span><span class="s">r-</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x10eebad30&gt;]
</code></pre></div></div>

<p><img src="2021-02-01-Gradietnt-Descent_files/2021-02-01-Gradietnt-Descent_17_1.png" alt="png" /></p>

<p>Firstly, if you are minimising the MSE you can compute it analytically via</p>

\[(A^T A)^{-1} A^Ty\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/08/13/Variants-of-Gradient-Descent-That-Are-Useful-To-Know.html"><h2 class="larger">Variants Of Gradient Descent That Are Useful To Know</h2></a>
          <br><span class="smaller">August 13, 2021</span>  <br/>
          <div><h1 id="variants-of-gradient-descent-which-are-useful-to-know">Variants of Gradient Descent which are useful to know</h1>

<p>Sometimes, pure gradient descent can be too slow, or for some other reason it’s not what you need. This post dicusses some alternatives.</p>

<p>First, we’ll make some classification data and run vanilla gradient descent to create a baseline for more exotic variants</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_circles</span>
<span class="kn">import</span> <span class="n">autograd.numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span> 
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="p">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="sh">'</span><span class="s">retina</span><span class="sh">'</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">([</span><span class="sh">'</span><span class="s">seaborn-colorblind</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">seaborn-darkgrid</span><span class="sh">'</span><span class="p">])</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">NUM_FEATURES</span><span class="o">=</span><span class="mi">6</span>
<span class="n">NUM_CLASSES</span><span class="o">=</span><span class="mi">2</span>
<span class="n">NUM_SAMPLES</span><span class="o">=</span><span class="mi">400</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">make_circles</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">NUM_SAMPLES</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="p">.</span><span class="mi">3</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="p">.</span><span class="mi">05</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">reds</span> <span class="o">=</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">0</span>
<span class="n">blues</span> <span class="o">=</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">1</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.collections.PathCollection at 0x1148cce48&gt;
</code></pre></div></div>

<p><img src="2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_files/2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_2_1.png" alt="png" /></p>

<p>This data is not linearly separable, so it’ll be difficult to classify these points using the same method we used last time. No fear though! We can add features to X which will make the data linearly seperable - we’ll transform X into a higher space. You can think of the current data set as points on a hill, and we’re looking down at them. If the blue points are higher than the red, then a plane which slices the hill in half will separate the data. The next function creates the extra columns which define the new space.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">quadratic_kernal</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Adds quadratic features. 
    This expansion allows your linear model to make non-linear separation.
    
    For each sample (row in matrix), compute an expanded row:
    [feature0, feature1, feature0^2, feature1^2, feature0*feature1, 1]
    
    :param X: matrix of features, shape [n_samples,2]
    :returns: expanded features of shape [n_samples,6]
    </span><span class="sh">"""</span>
    <span class="n">X_expanded</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="c1"># TODO:&lt;your code here&gt;
</span>    
    <span class="n">X_0_squared</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">X_1_squared</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">X_10</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    
    <span class="n">X_expanded</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">X_expanded</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">X_expanded</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_0_squared</span>
    <span class="n">X_expanded</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_1_squared</span>
    <span class="n">X_expanded</span><span class="p">[:,</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_10</span>
    <span class="n">X_expanded</span><span class="p">[:,</span> <span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],)).</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">X_expanded</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_kernal</span> <span class="o">=</span> <span class="nf">quadratic_kernal</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div>

<p>When we classified points in the last post, we used the sigmoid function to create probabioilties.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">prob</span>

<span class="k">def</span> <span class="nf">predict_prob</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">probs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">greater</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s try it out on some random data, and plot the predictions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">NUM_FEATURES</span><span class="p">,)</span>
<span class="n">y_probs</span> <span class="o">=</span> <span class="nf">predict_prob</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X_kernal</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">y_probs</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">reds</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span>
<span class="n">blues</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.collections.PathCollection at 0x114a935c0&gt;
</code></pre></div></div>

<p><img src="2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_files/2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_9_1.png" alt="png" /></p>

<p>As you can see, this gets everything wrong! Let’s try a better strategy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="nf">predict_prob</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="n">label_probabilities</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">*</span> <span class="n">targets</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">label_probabilities</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">loss</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X_kernal</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>357.50054021310473
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">autograd</span> <span class="kn">import</span> <span class="n">grad</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="nf">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">gradient_descent_auto</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">num_iters</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
    <span class="kn">from</span> <span class="n">autograd</span> <span class="kn">import</span> <span class="n">grad</span>
    <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,))</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="nf">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    <span class="k">yield</span> <span class="n">weights</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
        <span class="n">nabla</span> <span class="o">=</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">nabla</span>
        <span class="k">yield</span> <span class="n">weights</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weights</span> <span class="o">=</span> <span class="nf">gradient_descent_auto</span><span class="p">(</span><span class="n">X_kernal</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="n">costs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">w</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x1164a2780&gt;]
</code></pre></div></div>

<p><img src="2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_files/2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_15_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_probs</span> <span class="o">=</span> <span class="nf">predict_prob</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_kernal</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">y_probs</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">reds</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span>
<span class="n">blues</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.collections.PathCollection at 0x11519f080&gt;
</code></pre></div></div>

<p><img src="2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_files/2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_16_1.png" alt="png" /></p>

<p>Much better!</p>

<p>Gradient descent is taking a lot longer to converge in this setting. Let’s try a different variant of Gradient descent - one with momentum. Momentum is a method that helps accelerate gradient descent in the relevant direction and dampens oscillations as can be seen in image below. It does this by adding a fraction $\alpha$ of the update vector of the past time step to the current update vector.
<br />
<br /></p>

<p>\(\nu_t = \alpha \nu_{t-1} + \eta \nabla_w L(w_t, x_{i_j}, y_{i_j})\)
\(w_t = w_{t-1} - \nu_t\)</p>

<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent_with_momentum</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">num_iters</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
    <span class="kn">from</span> <span class="n">autograd</span> <span class="kn">import</span> <span class="n">grad</span>
    <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,))</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="nf">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    <span class="k">yield</span> <span class="n">weights</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
        <span class="n">nabla</span> <span class="o">=</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">nu</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">nu</span> <span class="o">+</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">nabla</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">nu</span>
        <span class="k">yield</span> <span class="n">weights</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weights</span> <span class="o">=</span> <span class="nf">gradient_descent_with_momentum</span><span class="p">(</span><span class="n">X_kernal</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="n">costs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">w</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x1147e8860&gt;]
</code></pre></div></div>

<p><img src="2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_files/2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_20_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_probs</span> <span class="o">=</span> <span class="nf">predict_prob</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_kernal</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">y_probs</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">reds</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span>
<span class="n">blues</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.collections.PathCollection at 0x116c33cf8&gt;
</code></pre></div></div>

<p><img src="2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_files/2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_21_1.png" alt="png" /></p>

<p>As you can see, this algorithm is converging faster than vanilla gradient descent! A final variant of Gradient Descent is RMSProp which uses squared gradients to adjust learning rate:</p>

<p>\(G_j^t = \alpha G_j^{t-1} + (1 - \alpha) g_{tj}^2\)
\(w_j^t = w_j^{t-1} - \dfrac{\eta}{\sqrt{G_j^t + \varepsilon}} g_{tj}\)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">RMSProp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">num_iters</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
    <span class="kn">from</span> <span class="n">autograd</span> <span class="kn">import</span> <span class="n">grad</span>
    <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,))</span>
    <span class="n">g2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-8</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="nf">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    <span class="k">yield</span> <span class="n">weights</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
        <span class="n">nabla</span> <span class="o">=</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">g2</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">g2</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">nabla</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">nabla</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">g2</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">weights</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weights</span> <span class="o">=</span> <span class="nc">RMSProp</span><span class="p">(</span><span class="n">X_kernal</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="n">costs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">w</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x116cd32b0&gt;]
</code></pre></div></div>

<p><img src="2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_files/2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_25_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_probs</span> <span class="o">=</span> <span class="nf">predict_prob</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_kernal</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">y_probs</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">reds</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span>
<span class="n">blues</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">reds</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">blues</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.collections.PathCollection at 0x116c89cc0&gt;
</code></pre></div></div>

<p><img src="2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_files/2021-08-13-Variants-of-Gradient-Descent-That-Are-Useful-To-Know_26_1.png" alt="png" /></p>

</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/08/13/Time-Series-with-GAMS.html"><h2 class="larger">Time Series With Gams</h2></a>
          <br><span class="smaller">August 13, 2021</span>  <br/>
          <div><p>This is a short post introducing Generalised Additive Models (GAMs) - not the nuts and bolts, but some things you can do with them. We will be follwoing this post: https://petolau.github.io/Analyzing-double-seasonal-time-series-with-GAM-in-R/ but we won’t go so deep into the theory, all the data come from the github repository linked in the post.</p>

<p>GAMs are a very flexible modelling technique, but unfortunately there isn’t a Python package as good as R’s <code class="language-plaintext highlighter-rouge">mgcv</code> yet. It’s something we’re working on! In this post, I’ll fit a simple GAM using <code class="language-plaintext highlighter-rouge">PyGAM</code> and in a later post I’ll talk about some theory, and some extensions.</p>

<p>GAMs are smooth, semi-parametric models of the form:</p>

\[y = \sum_{i=0}^{n-1} \beta_i f_i\left(x_i\right)\]

<p>where \(y\) is the dependent variable, \(x_i\) are the independent variables, \(\beta\) are the model coefficients, and \(f_i\) are the feature functions. We build the \(f_i\) using a type of function called a spline; splines allow us to automatically model non-linear relationships without having to manually try out many different transformations on each variable.</p>

<p>Nedt we’ll load some data and fit a GAM!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">feather</span>
<span class="kn">from</span> <span class="n">pygam</span> <span class="kn">import</span> <span class="n">LinearGAM</span>
<span class="kn">from</span> <span class="n">pygam.utils</span> <span class="kn">import</span> <span class="n">generate_X_grid</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="p">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="sh">'</span><span class="s">retina</span><span class="sh">'</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">([</span><span class="sh">'</span><span class="s">seaborn-colorblind</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">seaborn-darkgrid</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="nb">file</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">feather</span><span class="p">.</span><span class="nf">read_dataframe</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>

    <span class="n">weekday_map</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">Monday</span><span class="sh">'</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">Tuesday</span><span class="sh">'</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">Wednesday</span><span class="sh">'</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="sh">'</span><span class="s">Thursday</span><span class="sh">'</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="sh">'</span><span class="s">Friday</span><span class="sh">'</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="sh">'</span><span class="s">Saturday</span><span class="sh">'</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span> <span class="sh">'</span><span class="s">Sunday</span><span class="sh">'</span><span class="p">:</span><span class="mi">7</span><span class="p">}</span>
    <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">weekday</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">week</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">weekday_map</span><span class="p">)</span>

    <span class="n">n_type</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">n_date</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date_time</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">n_weekdays</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">weekday</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">period</span> <span class="o">=</span> <span class="mi">48</span>
    <span class="n">begin</span> <span class="o">=</span> <span class="sh">"</span><span class="s">2012-02-27</span><span class="sh">"</span>
    <span class="n">end</span> <span class="o">=</span> <span class="sh">"</span><span class="s">2012-03-12</span><span class="sh">"</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date_time</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">begin</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date_time</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">end</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">n_type</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="n">data</span> <span class="o">=</span> <span class="nf">load_data</span><span class="p">(</span><span class="sh">'</span><span class="s">DT_4_ind.dms</span><span class="sh">'</span><span class="p">)</span>

<span class="n">data</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">date_time</span><span class="sh">'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/thomas.kealy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
  app.launch_new_instance()





&lt;matplotlib.axes._subplots.AxesSubplot at 0x11f0bbac8&gt;
</code></pre></div></div>

<p><img src="2021-08-13-Time-Series-with-GAMS_files/2021-08-13-Time-Series-with-GAMS_2_2.png" alt="png" /></p>

<p>The above code loads some data, and does a little bit of preprocessing - makes weekday names more legible to humans, and just selects a few weeks of data about ‘Commerical Properties’. You can see that the time series has a lot of structure - exhibiting daily, but also weekly periodicity. There are 48 measurements during the day and 7 days during the week so that will be our independent variables to model response variable - electricity load. Let’s build it!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">period</span> <span class="o">=</span> <span class="mi">48</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># number of observations in the train set
</span><span class="n">window</span> <span class="o">=</span> <span class="n">N</span> <span class="o">/</span> <span class="n">period</span> <span class="c1"># number of days in the train set
</span>
<span class="n">weekly</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">weekday</span><span class="sh">'</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">period</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">daily</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">tile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nf">int</span><span class="p">(</span><span class="n">window</span><span class="p">))</span>

<span class="n">matrix_gam</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">daily</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">weekly</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">load</span><span class="sh">'</span><span class="p">])</span>
<span class="n">matrix_gam</span><span class="p">[</span><span class="sh">'</span><span class="s">load</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">]</span>
<span class="n">matrix_gam</span><span class="p">[</span><span class="sh">'</span><span class="s">daily</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">daily</span>
<span class="n">matrix_gam</span><span class="p">[</span><span class="sh">'</span><span class="s">weekly</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">weekly</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gam</span> <span class="o">=</span> <span class="nc">LinearGAM</span><span class="p">(</span><span class="n">n_splines</span><span class="o">=</span><span class="mi">10</span><span class="p">).</span><span class="nf">gridsearch</span><span class="p">(</span><span class="n">matrix_gam</span><span class="p">[[</span><span class="sh">'</span><span class="s">daily</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">weekly</span><span class="sh">'</span><span class="p">]],</span> <span class="n">matrix_gam</span><span class="p">[</span><span class="sh">'</span><span class="s">load</span><span class="sh">'</span><span class="p">])</span>
<span class="n">XX</span> <span class="o">=</span> <span class="nf">generate_X_grid</span><span class="p">(</span><span class="n">gam</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100% (11 of 11) |#########################| Elapsed Time: 0:00:00 Time: 0:00:00
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">set_figheight</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">set_figwidth</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">daily</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">weekly</span><span class="sh">'</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span>
    <span class="n">pdep</span><span class="p">,</span> <span class="n">confi</span> <span class="o">=</span> <span class="n">gam</span><span class="p">.</span><span class="nf">partial_dependence</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>
    <span class="n">confi</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">asarray</span><span class="p">(</span><span class="n">confi</span><span class="p">)</span>
    <span class="n">confi</span> <span class="o">=</span> <span class="n">confi</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">()</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">XX</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">pdep</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">XX</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">confi</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="2021-08-13-Time-Series-with-GAMS_files/2021-08-13-Time-Series-with-GAMS_6_0.png" alt="png" /></p>

<p>This is good! You can see that the electricity load follows an approximate <code class="language-plaintext highlighter-rouge">sin</code> pattern during the day, and that the electricity load falls off during the week! If we’d tried using a linear model to do this, we’d have had to build these features manually - the good thing about GAMs is that they do this for us. Let’s visualise the fit.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictions</span> <span class="o">=</span> <span class="n">gam</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">matrix_gam</span><span class="p">[[</span><span class="sh">'</span><span class="s">daily</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">weekly</span><span class="sh">'</span><span class="p">]])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">date_time</span><span class="sh">'</span><span class="p">],</span> <span class="n">matrix_gam</span><span class="p">[</span><span class="sh">'</span><span class="s">load</span><span class="sh">'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">date_time</span><span class="sh">'</span><span class="p">],</span> <span class="n">predictions</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Predicted</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x11eb87f28&gt;
</code></pre></div></div>

<p><img src="2021-08-13-Time-Series-with-GAMS_files/2021-08-13-Time-Series-with-GAMS_9_1.png" alt="png" /></p>

<p>Alas, this isn’t the best fit, but it’ll do!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/08/13/Structural-Time-Series-in-PyMC3.html"><h2 class="larger">Structural time series in pymc3</h2></a>
          <br><span class="smaller">August 13, 2021</span>  <br/>
          <div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="n">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pylab</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">matplotlib.dates</span> <span class="k">as</span> <span class="n">mdates</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">pymc3</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="n">arviz</span> <span class="k">as</span> <span class="n">az</span>

<span class="kn">from</span> <span class="n">pandas.plotting</span> <span class="kn">import</span> <span class="n">register_matplotlib_converters</span>
<span class="nf">register_matplotlib_converters</span><span class="p">()</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">set_context</span><span class="p">(</span><span class="sh">"</span><span class="s">notebook</span><span class="sh">"</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">set_style</span><span class="p">(</span><span class="sh">"</span><span class="s">darkgrid</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">passengers</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">passengers.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="sh">'</span><span class="s">;</span><span class="sh">'</span><span class="p">)</span>
<span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Month</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Month</span><span class="sh">'</span><span class="p">])</span>
<span class="n">passengers</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">Month</span><span class="sh">'</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">passengers</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x134a79d50&gt;
</code></pre></div></div>

<p><img src="2021-08-13-Structural%20Time%20Series%20in%20PyMC3_files/2021-08-13-Structural%20Time%20Series%20in%20PyMC3_1_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>112.0
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Model</span><span class="p">():</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">GaussianRandomWalk</span><span class="p">(</span><span class="sh">'</span><span class="s">delta</span><span class="sh">'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">144</span><span class="p">,))</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">GaussianRandomWalk</span><span class="p">(</span><span class="sh">'</span><span class="s">mu</span><span class="sh">'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">delta</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">143</span><span class="p">,),</span> <span class="n">observed</span><span class="o">=</span><span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [delta]
</code></pre></div></div>

<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value="24000" class="" max="24000" style="width:300px; height:20px; vertical-align: middle;"></progress>
  100.00% [24000/24000 00:11&lt;00:00 Sampling 4 chains, 0 divergences]
</div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 20 seconds.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="nf">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/tomkealy/opt/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:91: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.
  FutureWarning,
/Users/tomkealy/opt/anaconda3/lib/python3.7/site-packages/arviz/plots/traceplot.py:195: UserWarning: rcParams['plot.max_subplots'] (20) is smaller than the number of variables to plot (144), generating only 20 plots
  UserWarning,





array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x132062690&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x13210eed0&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x134d33350&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1321ceed0&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x13595a9d0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x132154a90&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x13229f650&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x132384b50&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1323c2f90&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1324bc7d0&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1324fcb50&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1325eaed0&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x132639bd0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x132727cd0&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x132773850&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x132862d10&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1328a6fd0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x13299d990&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1329e0c10&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x132ad8610&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x132b1ad90&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x132c08f50&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x132c91a10&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x132d57ad0&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x132da6690&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x132e96b50&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x132ed8f50&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x132fcf7d0&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x133014b50&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x133101ed0&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x13314dbd0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x13323ccd0&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1332d0850&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x133395d10&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1333d9fd0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1334cf990&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x133511c10&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x13360c610&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x13364cd90&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x133739f50&gt;]],
      dtype=object)
</code></pre></div></div>

<p><img src="2021-08-13-Structural%20Time%20Series%20in%20PyMC3_files/2021-08-13-Structural%20Time%20Series%20in%20PyMC3_4_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_forecast</span><span class="p">(</span><span class="n">data_df</span><span class="p">,</span>
                  <span class="n">col_name</span><span class="p">,</span>
                  <span class="n">forecast_start</span><span class="p">,</span>
                  <span class="n">forecast_mean</span><span class="p">,</span> 
                  <span class="n">forecast_scale</span><span class="p">,</span> 
                  <span class="n">forecast_samples</span><span class="p">,</span>
                  <span class="n">title</span><span class="p">,</span> 
                  <span class="n">x_locator</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                  <span class="n">x_formatter</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Plot a forecast distribution against the </span><span class="sh">'</span><span class="s">true</span><span class="sh">'</span><span class="s"> time series.</span><span class="sh">"""</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">()</span>
    <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">data_df</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">data_df</span><span class="p">.</span><span class="n">index</span>

    <span class="n">num_steps</span> <span class="o">=</span> <span class="n">data_df</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_steps_forecast</span> <span class="o">=</span> <span class="n">forecast_mean</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">num_steps_train</span> <span class="o">=</span> <span class="n">num_steps</span> <span class="o">-</span> <span class="n">num_steps_forecast</span>

    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">c1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">ground truth</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">forecast_steps</span> <span class="o">=</span> <span class="n">data_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">forecast_start</span><span class="p">:].</span><span class="n">index</span>

    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">,</span> 
            <span class="n">forecast_samples</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> 
            <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
            <span class="n">color</span><span class="o">=</span><span class="n">c2</span><span class="p">,</span> 
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">,</span> 
            <span class="n">forecast_mean</span><span class="p">,</span> 
            <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
            <span class="n">ls</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> 
            <span class="n">color</span><span class="o">=</span><span class="n">c2</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">forecast</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">,</span>
                   <span class="n">forecast_mean</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">forecast_scale</span><span class="p">,</span>
                   <span class="n">forecast_mean</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">forecast_scale</span><span class="p">,</span> 
                   <span class="n">color</span><span class="o">=</span><span class="n">c2</span><span class="p">,</span> 
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">forecast_samples</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="nf">max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">forecast_samples</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">yrange</span> <span class="o">=</span> <span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">([</span><span class="n">ymin</span> <span class="o">-</span> <span class="n">yrange</span><span class="o">*</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">+</span> <span class="n">yrange</span><span class="o">*</span><span class="mf">0.1</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="nf">plot_forecast</span><span class="p">(</span>
    <span class="n">passengers</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">1959-01-01</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">forecast_mean</span><span class="p">,</span> 
    <span class="n">forecast_scale</span><span class="p">,</span> 
    <span class="n">forecast_samples</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="sh">'</span><span class="s">Airplane Passenger Numbers</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">"</span><span class="s">upper left</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Passenger Numbers</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Month</span><span class="sh">"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">autofmt_xdate</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

&lt;ipython-input-4-d3135643ac66&gt; in &lt;module&gt;
     54     'Passengers',
     55     '1959-01-01',
---&gt; 56     forecast_mean,
     57     forecast_scale,
     58     forecast_samples,


NameError: name 'forecast_mean' is not defined
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/08/12/Time-Series-Forecasting-With-SARIMAX.html"><h2 class="larger">Time Series Forecasting With Sarimax</h2></a>
          <br><span class="smaller">August 12, 2021</span>  <br/>
          <div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">'</span><span class="s">ggplot</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">passengers</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">passengers.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="sh">'</span><span class="s">;</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Month</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">passengers</span> <span class="o">=</span> <span class="n">passengers</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">datetime</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">passengers</span> <span class="o">=</span> <span class="n">passengers</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">Month</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">mpl</span><span class="p">.</span><span class="nf">rc_context</span><span class="p">():</span>
    <span class="n">mpl</span><span class="p">.</span><span class="nf">rc</span><span class="p">(</span><span class="sh">"</span><span class="s">figure</span><span class="sh">"</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">passengers</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">observed</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="2021-08-12-Time-Series-Forecasting-With-SARIMAX_files/2021-08-12-Time-Series-Forecasting-With-SARIMAX_5_0.png" alt="png" /></p>

<p>Let’s fit a simple ARIMA model, where we simply chose 1 AR order and 1 MA order. We also include seasonality of 12 months in this regression - but there’s no need to worry about it!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">IPython.core.debugger</span> <span class="kn">import</span> <span class="n">set_trace</span>

<span class="k">def</span> <span class="nf">meboot</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">num_replicates</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">
    Maximum Entropy Time Series Bootstrap as described in:
    https://cran.r-project.org/web/packages/meboot/vignettes/meboot.pdf
    The algorithm (described below) creates an (x.shape[0], num_replicates) DataFrame of replicated time series designed to mimic the properties of the given time series. Bootstrap samples are used to study the relation between the sample and the (unknown) population by a comparible relation between the sample at hand and appropriately designed (observable) resamples. The Maximum Entropy (ME) Bootstrap extends the traditional bootstrap to nonstationary dependent data.
    Original R source code:
    https://rdrr.io/cran/meboot/f/
    The steps of the algorithm are:
    1. Sort the original data in increasing order to create order statistics x_(t) t=1,...,T and store the ordering index vector.
    2. Compute intermediate points z_t = (x_(t) + x_(t+1))/2 from the order statistics
    3. Compute the trimmed mean, m_trimmed, of the deviations x_t - x_{t-1} among all consecutive observations. Compute the lower limit for the left tail as x_(1) - m_trimmed and the upper limie for the right tail as x_(T) + m_trimmed. The limits become the limiting intermediate points.
    4. Compute the mean of the maximum entropy density within each interval such that the </span><span class="sh">'</span><span class="s">mean preserving constraint</span><span class="sh">'</span><span class="s"> (designed to satify the ergodic theorem) is satisfied. Interval means are denoted m_t. The means for the first and last interval have simpler formulas.
    5. Generate random numbers from the [0, 1] uniform interval, and compute sample quantiels of the ME density at those points and sort them.
    6. Reorder the sorted sample quantiles by using the ordering index of step 1. This recovers the time dependence relationships of the originally observed data.
    7. Repeat steps 2 to 6 num_replicates times.
    Parameters
    ----------------------
    x : pd.Series
      The original Time Series to create replicates for.
    num_replicates : int
      The number of replicates to create.
    Returns
    -----------------------
    replicates : pd.DataFrame
      A (x.shape[0], num_replicates) DataFrame containing the Maximum Entropy replicates of x as columns.
    Examples
    -----------------------
    x = my_series
    replicates = meboot(x, num_replicates=100)
    </span><span class="sh">'''</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">):</span>
        <span class="k">raise</span> <span class="nc">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">`x` should be a pandas.Series</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># 1
</span>    <span class="n">sorted_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">()</span>
    <span class="n">xt</span> <span class="o">=</span> <span class="n">sorted_x</span><span class="p">.</span><span class="n">values</span>

    <span class="c1"># 3 + 2
</span>    <span class="n">trimmed_mean</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">diff</span><span class="p">().</span><span class="nf">abs</span><span class="p">().</span><span class="nf">mean</span><span class="p">()</span>
    <span class="n">zt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">((</span>
        <span class="n">xt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">trimmed_mean</span><span class="p">,</span>
        <span class="p">(</span><span class="n">xt</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">xt</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">xt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">trimmed_mean</span>
    <span class="p">))</span>

    <span class="c1"># 4
</span>    <span class="n">desired_means</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">((</span>
        <span class="mf">0.75</span> <span class="o">*</span> <span class="n">xt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="n">xt</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="mf">0.25</span> <span class="o">*</span> <span class="n">xt</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">xt</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="n">xt</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span>
        <span class="mf">0.75</span> <span class="o">*</span> <span class="n">xt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="n">xt</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="p">))</span>

    <span class="c1"># 5
</span>    <span class="n">xr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">num_replicates</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">))).</span><span class="nf">transpose</span><span class="p">()</span>
    <span class="n">inds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">searchsorted</span><span class="p">(</span><span class="n">xr</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">lin_interp</span> <span class="o">=</span> <span class="n">desired_means</span><span class="p">[</span><span class="n">inds</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">zt</span><span class="p">[</span><span class="n">inds</span><span class="p">]</span> <span class="o">-</span> <span class="n">zt</span><span class="p">[</span><span class="n">inds</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="n">zt</span><span class="p">[</span><span class="n">inds</span><span class="p">]</span> <span class="o">+</span> <span class="n">lin_interp</span>
    <span class="n">y1</span> <span class="o">=</span> <span class="n">zt</span><span class="p">[</span><span class="n">inds</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">lin_interp</span>

    <span class="n">quantiles</span> <span class="o">=</span> <span class="p">(</span><span class="n">y0</span> <span class="o">+</span> <span class="p">((</span><span class="n">U</span> <span class="o">-</span> <span class="n">xr</span><span class="p">[</span><span class="n">inds</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">y1</span> <span class="o">-</span> <span class="n">y0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">xr</span><span class="p">[</span><span class="n">inds</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">xr</span><span class="p">[</span><span class="n">inds</span><span class="p">]))</span>
    <span class="n">replicates</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">quantiles</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">sorted_x</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>

    <span class="c1"># 6
</span>    <span class="k">return</span> <span class="n">replicates</span><span class="p">.</span><span class="nf">reindex</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">passengers</span>
<span class="n">col</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span>
<span class="n">replicates</span> <span class="o">=</span> <span class="nf">meboot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">num_replicates</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">replicates</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11fd92f28&gt;
</code></pre></div></div>

<p><img src="2021-08-12-Time-Series-Forecasting-With-SARIMAX_files/2021-08-12-Time-Series-Forecasting-With-SARIMAX_9_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">replicates</span><span class="p">[</span><span class="mi">50</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">passengers</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11fd92d68&gt;
</code></pre></div></div>

<p><img src="2021-08-12-Time-Series-Forecasting-With-SARIMAX_files/2021-08-12-Time-Series-Forecasting-With-SARIMAX_10_1.png" alt="png" /></p>

<p><img src="2021-08-12-Time-Series-Forecasting-With-SARIMAX_files/2021-08-12-Time-Series-Forecasting-With-SARIMAX_10_2.png" alt="png" /></p>

</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/08/10/The-Guts-Of-GAMs.html"><h2 class="larger">The Guts Of Gams</h2></a>
          <br><span class="smaller">August 10, 2021</span>  <br/>
          <div><p>This post will explain some of the internals of GAMs: how to estimate the feature functions. First we’ll fit some simple splines on some wage data, then we’ll fit more complicated splines on some accelerometer data, with a highly non-linear realtionship between in the input and the output.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">patsy</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">import</span> <span class="n">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">import</span> <span class="n">statsmodels.formula.api</span> <span class="k">as</span> <span class="n">smf</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/thomas.kealy/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
</code></pre></div></div>

<p>GAMs are smooth, semi-parametric models of the form:</p>

\[y = \sum_{i=0}^{n-1} \beta_i f_i\left(x_i\right)\]

<p>where \(y\) is the dependent variable, \(x_i\) are the independent variables, \(\beta\) are the model coefficients, and \(f_i\) are the feature functions.</p>

<p>We build the \(f_i\) using a type of function called a spline; splines allow us to automatically model non-linear relationships without having to manually try out many different transformations on each variable.</p>

<p>First of all, we’ll use <code class="language-plaintext highlighter-rouge">patsy</code> to construct a few spline bases and fit generalised linear models with <code class="language-plaintext highlighter-rouge">statsmodels</code>. Then, we’ll dive into constructing splines ourselves; following Simon Wood’s book we’ll use penalised regression splines.</p>

<p>Firstly, we’ll use <code class="language-plaintext highlighter-rouge">patsy</code> to create some basic pline models. The data we’re using comes from https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Wage.html. It’s plotted below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">Wage.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">age_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nf">max</span><span class="p">()).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">wage</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.collections.PathCollection at 0x11d0a5898&gt;
</code></pre></div></div>

<p><img src="2021-08-10-The-Guts-Of-GAMs_files/2021-08-10-The-Guts-Of-GAMs_3_1.png" alt="png" /></p>

<p>GAMs are essentially linear models, but in a very special (and useful!) basis made of regression splines. We can use the <code class="language-plaintext highlighter-rouge">bs()</code> function in <code class="language-plaintext highlighter-rouge">patsy</code> to create such a basis for us:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transformed_x1</span> <span class="o">=</span> <span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">"</span><span class="s">bs(df.age, knots=(25,40,60), degree=3, include_intercept=False)</span><span class="sh">"</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">df.age</span><span class="sh">"</span><span class="p">:</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">},</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">dataframe</span><span class="sh">'</span><span class="p">)</span>
<span class="n">fit1</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">GLM</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">wage</span><span class="p">,</span> <span class="n">transformed_x1</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fit1</span><span class="p">.</span><span class="n">params</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intercept                                                               60.493714
bs(df.age, knots=(25, 40, 60), degree=3, include_intercept=False)[0]     3.980500
bs(df.age, knots=(25, 40, 60), degree=3, include_intercept=False)[1]    44.630980
bs(df.age, knots=(25, 40, 60), degree=3, include_intercept=False)[2]    62.838788
bs(df.age, knots=(25, 40, 60), degree=3, include_intercept=False)[3]    55.990830
bs(df.age, knots=(25, 40, 60), degree=3, include_intercept=False)[4]    50.688098
bs(df.age, knots=(25, 40, 60), degree=3, include_intercept=False)[5]    16.606142
dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">age_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nf">max</span><span class="p">()).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">fit1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">"</span><span class="s">bs(age_grid, knots=(25,40,60), include_intercept=False)</span><span class="sh">"</span><span class="p">,</span>
<span class="p">{</span><span class="sh">"</span><span class="s">age_grid</span><span class="sh">"</span><span class="p">:</span> <span class="n">age_grid</span><span class="p">},</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">dataframe</span><span class="sh">'</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">wage</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">age_grid</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Specifying three knots</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">85</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">350</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">wage</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0,0.5,'wage')
</code></pre></div></div>

<p><img src="2021-08-10-The-Guts-Of-GAMs_files/2021-08-10-The-Guts-Of-GAMs_7_1.png" alt="png" /></p>

<p>Here we have prespecified knots at ages 25, 40, and 60. This produces a spline with six basis functions. A cubic spline has 7 degrees of freedom: one for the intercept, and two for each order. We could also have specified knot points at uniform quantiles of the data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Specifying 6 degrees of freedom
</span><span class="n">transformed_x2</span> <span class="o">=</span> <span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">"</span><span class="s">bs(df.age, df=6, include_intercept=False)</span><span class="sh">"</span><span class="p">,</span>
<span class="p">{</span><span class="sh">"</span><span class="s">df.age</span><span class="sh">"</span><span class="p">:</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">},</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">dataframe</span><span class="sh">'</span><span class="p">)</span>
<span class="n">fit2</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">GLM</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">wage</span><span class="p">,</span> <span class="n">transformed_x2</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">fit2</span><span class="p">.</span><span class="n">params</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intercept                                       56.313841
bs(df.age, df=6, include_intercept=False)[0]    27.824002
bs(df.age, df=6, include_intercept=False)[1]    54.062546
bs(df.age, df=6, include_intercept=False)[2]    65.828391
bs(df.age, df=6, include_intercept=False)[3]    55.812734
bs(df.age, df=6, include_intercept=False)[4]    72.131473
bs(df.age, df=6, include_intercept=False)[5]    14.750876
dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">age_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nf">max</span><span class="p">()).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">fit2</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">"</span><span class="s">bs(age_grid, df=6, include_intercept=False)</span><span class="sh">"</span><span class="p">,</span>
<span class="p">{</span><span class="sh">"</span><span class="s">age_grid</span><span class="sh">"</span><span class="p">:</span> <span class="n">age_grid</span><span class="p">},</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">dataframe</span><span class="sh">'</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">wage</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">age_grid</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Specifying three knots</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">85</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">350</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">wage</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0,0.5,'wage')
</code></pre></div></div>

<p><img src="2021-08-10-The-Guts-Of-GAMs_files/2021-08-10-The-Guts-Of-GAMs_10_1.png" alt="png" /></p>

<p>Finally, we can also fit natural splines with the <code class="language-plaintext highlighter-rouge">cr()</code> function:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Specifying 4 degrees of freedom
</span><span class="n">transformed_x3</span> <span class="o">=</span> <span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">"</span><span class="s">cr(df.age, df=4)</span><span class="sh">"</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">df.age</span><span class="sh">"</span><span class="p">:</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">},</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">dataframe</span><span class="sh">'</span><span class="p">)</span>
<span class="n">fit3</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">GLM</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">wage</span><span class="p">,</span> <span class="n">transformed_x3</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">fit3</span><span class="p">.</span><span class="n">params</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intercept             -6.970341e+13
cr(df.age, df=4)[0]    6.970341e+13
cr(df.age, df=4)[1]    6.970341e+13
cr(df.age, df=4)[2]    6.970341e+13
cr(df.age, df=4)[3]    6.970341e+13
dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred</span> <span class="o">=</span> <span class="n">fit3</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">"</span><span class="s">cr(age_grid, df=4)</span><span class="sh">"</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">age_grid</span><span class="sh">"</span><span class="p">:</span> <span class="n">age_grid</span><span class="p">},</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">dataframe</span><span class="sh">'</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">wage</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">age_grid</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">g</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Natural spline df=4</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">85</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">350</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">wage</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0,0.5,'wage')
</code></pre></div></div>

<p><img src="2021-08-10-The-Guts-Of-GAMs_files/2021-08-10-The-Guts-Of-GAMs_13_1.png" alt="png" /></p>

<p>Let’s see how these fits all stack together:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generate a sequence of age values spanning the range
</span><span class="n">age_grid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nf">max</span><span class="p">()).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Make some predictions
</span><span class="n">pred1</span> <span class="o">=</span> <span class="n">fit1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">"</span><span class="s">bs(age_grid, knots=(25,40,60), include_intercept=False)</span><span class="sh">"</span><span class="p">,</span>
<span class="p">{</span><span class="sh">"</span><span class="s">age_grid</span><span class="sh">"</span><span class="p">:</span> <span class="n">age_grid</span><span class="p">},</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">dataframe</span><span class="sh">'</span><span class="p">))</span>
<span class="n">pred2</span> <span class="o">=</span> <span class="n">fit2</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">"</span><span class="s">bs(age_grid, df=6, include_intercept=False)</span><span class="sh">"</span><span class="p">,</span>
<span class="p">{</span><span class="sh">"</span><span class="s">age_grid</span><span class="sh">"</span><span class="p">:</span> <span class="n">age_grid</span><span class="p">},</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">dataframe</span><span class="sh">'</span><span class="p">))</span>
<span class="n">pred3</span> <span class="o">=</span> <span class="n">fit3</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">"</span><span class="s">cr(age_grid, df=4)</span><span class="sh">"</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">age_grid</span><span class="sh">"</span><span class="p">:</span> <span class="n">age_grid</span><span class="p">},</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">dataframe</span><span class="sh">'</span><span class="p">))</span>
<span class="c1"># Plot the splines and error bands
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">wage</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">age_grid</span><span class="p">,</span> <span class="n">pred1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Specifying three knots</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">age_grid</span><span class="p">,</span> <span class="n">pred2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Specifying df=6</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">age_grid</span><span class="p">,</span> <span class="n">pred3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">g</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Natural spline df=4</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">85</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">350</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">wage</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0,0.5,'wage')
</code></pre></div></div>

<p><img src="2021-08-10-The-Guts-Of-GAMs_files/2021-08-10-The-Guts-Of-GAMs_15_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">patsy</span>
<span class="kn">import</span> <span class="n">scipy</span> <span class="k">as</span> <span class="n">sp</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="n">statsmodels</span> <span class="kn">import</span> <span class="n">api</span> <span class="k">as</span> <span class="n">sm</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">mcycle.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">Unnamed: 0</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">blue</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">accel</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">blue</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">time</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Acceleration</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0,0.5,'Acceleration')
</code></pre></div></div>

<p><img src="2021-08-10-The-Guts-Of-GAMs_files/2021-08-10-The-Guts-Of-GAMs_18_1.png" alt="png" /></p>

<p>As discussed earlier: GAMs are smooth, semi-parametric models of the form:
​
\(y = \sum_{i=0}^{n-1} \beta_i f_i\left(x_i\right)\)
​
where \(y\) is the dependent variable, \(x_i\) are the independent variables, \(\beta\) are the model coefficients, and \(f_i\) are the feature functions.
​
We build the \(f_i\) using a type of function called a spline. Since our data is 1D, we can model it as:</p>

\[y = \beta_0 + f\left( x \right) + \varepsilon\]

<p>We must also choose a basis for \( f \):</p>

\[f \left( x \right) = \beta_1 B_1\left(x\right) + \ldots + \beta_k B_k\left(x\right)\]

<p>We define</p>

\[X = \left[1, x_1,  \ldots,  x_k \right]\]

<p>so we can write:</p>

<p>$ y = \beta_0 + f\left( x \right) + \varepsilon = X\beta + \varepsilon $$</p>

<p>We choose to minimise the sum of squares again, this time with a regularisation term:</p>

\[\frac{1}{2} \lVert y - X\beta \rVert + \lambda \int_0^1 f''\left(x\right)^2 dx\]

<p>You can show (you, not me!) that the second term can always be written:</p>

\[\int_0^1 f''\left(x\right)^2 dx = \beta^T S \beta\]

<p>where \( S \) is a postive (semi)-definiate matrix (i.e. all it’s eigenvalues are positive or 0). Therefore our objective function becomes:</p>

\[\frac{1}{2} \lVert y - X\beta \rVert + \lambda \beta^T S \beta dx\]

<p>and we can use the techniques we’ve developed fitting linear models to fit additive models! We’ll start by fitting a univariate spline, then maybe something more complicated.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">R</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="nf">return </span><span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">12</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">12</span><span class="p">)</span> <span class="o">/</span> <span class="mi">4</span> <span class="o">-</span> <span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">4</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">7</span> <span class="o">/</span> <span class="mi">240</span><span class="p">)</span> <span class="o">/</span> <span class="mi">24</span>

<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">frompyfunc</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">R_</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">R</span><span class="p">.</span><span class="nf">outer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">knots</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">q</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">knots</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">.</span><span class="nf">quantile</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">q</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrices</span><span class="p">(</span><span class="sh">'</span><span class="s">accel ~ times + R_(times)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">q</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">q</span> <span class="o">+</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">S</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="nc">R_</span><span class="p">(</span><span class="n">knots</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
<span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">real_if_close</span><span class="p">(</span><span class="n">sp</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">sqrtm</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span> <span class="mi">2</span><span class="p">:]),</span> <span class="n">tol</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="mi">8</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/thomas.kealy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ComplexWarning: Casting complex values to real discards the imaginary part
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="c1"># build the augmented matrices
</span>    <span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">q</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))))</span>
    <span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">lambda_</span><span class="p">)</span> <span class="o">*</span> <span class="n">B</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span> <span class="n">X_</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">min_time</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">.</span><span class="nf">min</span><span class="p">()</span>
<span class="n">max_time</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span>

<span class="n">plot_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">min_time</span><span class="p">,</span> <span class="n">max_time</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plot_X</span> <span class="o">=</span> <span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">'</span><span class="s">times + R_(times)</span><span class="sh">'</span><span class="p">,</span> <span class="p">{</span><span class="sh">'</span><span class="s">times</span><span class="sh">'</span><span class="p">:</span> <span class="n">plot_x</span><span class="p">})</span>

<span class="n">results</span> <span class="o">=</span> <span class="nf">fit</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">blue</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">accel</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">blue</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">plot_x</span><span class="p">,</span> <span class="n">results</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">plot_X</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">time</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">accel</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$\lambda = {}$</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5,1,'$\\lambda = 1.0$')
</code></pre></div></div>

<p><img src="2021-08-10-The-Guts-Of-GAMs_files/2021-08-10-The-Guts-Of-GAMs_27_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/06/21/Neural-Netwroks-From-Scratch.html"><h2 class="larger">Neural Netwroks From Scratch</h2></a>
          <br><span class="smaller">June 21, 2021</span>  <br/>
          <div><p>It’s useful sometimes to write simple versions of complex things, so that you understand them. In this post we write a simple neural network from scratch.</p>

<p>In a normal classification problem, we have some labels (y) and inputs (x) and we would like to learn a linear function</p>

\[y = W x\]

<p>to separate the classes. Neural networks add an (or many!) extra layer</p>

\[h = \mathrm{sigmoid}(M x)\]

<p>between the inputs and output so that it produces is</p>

\[y = W h\]

<p>Thus we are esentially fitting a linear classifier on the basis expansion (\mathrm{sigmoid}(M x)), the difference being that w efit the basis expansion, as well as the linear classifier. That is the Network learns a data dependent basis on which to clssify.</p>

<p>Enough with the maths, lets do some coding.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<p>Neural networks are made up of Layers, the simplest just returns what it recieves as input.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    A building block. Each layer is capable of performing two things:
    
    - Process input to get output:           output = layer.forward(input)
    
    - Propagate gradients through itself:    grad_input = layer.backward(input, grad_output)
    
    Some layers also have learnable parameters which they update during layer.backward.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">This is an identity layer so it doesn</span><span class="sh">'</span><span class="s">t need to do anything.</span><span class="sh">"""</span>
        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Parameters
        ----------
        input : Tensor of shape [batch_size, num_input_units]
        
        Returns
        ----------
        output: Tensor of shape [batch_size, num_output_units]

        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="nb">input</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Performs a backpropagation step through the layer, with respect to the given input.
        
        Parameters
        ----------
        input : Tensor of shape [batch_size, num_input_units]
        
        grad_output : Tensor of shape  [batch_size, num_input_units]
        
        Returns
        ----------
        
        grad_output : Tensor of shape [batch_size, num_output_units]
        
        </span><span class="sh">"""</span>
        
        <span class="n">num_units</span> <span class="o">=</span> <span class="nb">input</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">d_layer_d_input</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">num_units</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">grad_output</span><span class="p">,</span> <span class="n">d_layer_d_input</span><span class="p">)</span> <span class="c1"># chain rule
</span></code></pre></div></div>

<p>Lets add some non-linearity layers: a ReLU layer, and a Sigmoid layer</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">ReLU layer simply applies elementwise rectified linear unit to all inputs</span><span class="sh">"""</span>
        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Apply elementwise ReLU to [batch, input_units] matrix
        
        Parameters
        ----------
        input : Tensor of shape [batch_size, num_input_units]
        
        Returns
        ----------
        output: Tensor of shape [batch_size, num_output_units]

        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
        
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Compute gradient of loss w.r.t. ReLU input
                
        Parameters
        ----------
        input : Tensor of shape [batch_size, num_input_units]
        
        grad_output : Tensor of shape  [batch_size, num_input_units]
        
        Returns
        ----------
        
        grad_output : Tensor of shape [batch_size, num_output_units]
        </span><span class="sh">"""</span>
        <span class="n">relu_grad</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">grad_output</span><span class="o">*</span><span class="n">relu_grad</span>        
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Sigmoid layer simply applies elementwise sigmoid unit to all inputs</span><span class="sh">"""</span>
        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Apply elementwise ReLU to [batch, input_units] matrix
        
        Parameters
        ----------
        input : Tensor of shape [batch_size, num_input_units]
        
        Returns
        ----------
        output: Tensor of shape [batch_size, num_output_units]

        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Compute gradient of loss w.r.t. ReLU input
                
        Parameters
        ----------
        input : Tensor of shape [batch_size, num_input_units]
        
        grad_output : Tensor of shape  [batch_size, num_input_units]
        
        Returns
        ----------
        
        grad_output : Tensor of shape [batch_size, num_output_units]
        </span><span class="sh">"""</span>
        <span class="n">sigmoid_grad</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">grad_output</span><span class="o">*</span><span class="n">sigmoid_grad</span>        
</code></pre></div></div>

<p>We can test this by evaluating the numerical gradients:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">eval_numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Evaluates gradient df/dx via finite differences:
    df/dx ~ (f(x+h) - f(x-h)) / 2h
    Adopted from https://github.com/ddtm/dl-course/ (our ysda course).
    </span><span class="sh">"""</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># evaluate function value at original point
</span>    <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># iterate over all indexes in x
</span>    <span class="n">it</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">nditer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">multi_index</span><span class="sh">'</span><span class="p">],</span> <span class="n">op_flags</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">readwrite</span><span class="sh">'</span><span class="p">])</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">it</span><span class="p">.</span><span class="n">finished</span><span class="p">:</span>

        <span class="c1"># evaluate function at x+h
</span>        <span class="n">ix</span> <span class="o">=</span> <span class="n">it</span><span class="p">.</span><span class="n">multi_index</span>
        <span class="n">oldval</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span>
        <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">oldval</span> <span class="o">+</span> <span class="n">h</span> <span class="c1"># increment by h
</span>        <span class="n">fxph</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># evalute f(x + h)
</span>        <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">oldval</span> <span class="o">-</span> <span class="n">h</span>
        <span class="n">fxmh</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># evaluate f(x - h)
</span>        <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">oldval</span> <span class="c1"># restore
</span>
        <span class="c1"># compute the partial derivative with centered formula
</span>        <span class="n">grad</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fxph</span> <span class="o">-</span> <span class="n">fxmh</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">h</span><span class="p">)</span> <span class="c1"># the slope
</span>        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nf">print </span><span class="p">(</span><span class="n">ix</span><span class="p">,</span> <span class="n">grad</span><span class="p">[</span><span class="n">ix</span><span class="p">])</span>
        <span class="n">it</span><span class="p">.</span><span class="nf">iternext</span><span class="p">()</span> <span class="c1"># step to next dimension
</span>
    <span class="k">return</span> <span class="n">grad</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="o">*</span><span class="mi">32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">32</span><span class="p">])</span>
<span class="n">l</span> <span class="o">=</span> <span class="nc">ReLU</span><span class="p">()</span>
<span class="n">grads</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="nf">backward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">32</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="mi">32</span><span class="o">*</span><span class="mi">10</span><span class="p">))</span>
<span class="n">numeric_grads</span> <span class="o">=</span> <span class="nf">eval_numerical_gradient</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">l</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">numeric_grads</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>\
    <span class="sh">"</span><span class="s">gradient returned by your layer does not match the numerically computed gradient</span><span class="sh">"</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="o">*</span><span class="mi">32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">32</span><span class="p">])</span>
<span class="n">l</span> <span class="o">=</span> <span class="nc">Sigmoid</span><span class="p">()</span>
<span class="n">grads</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="nf">backward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">32</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="mi">32</span><span class="o">*</span><span class="mi">10</span><span class="p">))</span>
<span class="n">numeric_grads</span> <span class="o">=</span> <span class="nf">eval_numerical_gradient</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">l</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">numeric_grads</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>\
    <span class="sh">"</span><span class="s">gradient returned by your layer does not match the numerically computed gradient</span><span class="sh">"</span>
</code></pre></div></div>

<p>The next type of layer we will implement will be a Dense or Fully Connected layer. Unlike nonlinearity, this layer actually has something to learn.</p>

<p>A dense layer applies affine transformation. In a vectorized form, it can be described as:
\(f(X)= W \cdot X + \vec b\)</p>

<p>Where</p>
<ul>
  <li>X is an object-feature matrix of shape [batch_size, num_features],</li>
  <li>W is a weight matrix [num_features, num_outputs]</li>
  <li>and b is a vector of num_outputs biases.</li>
</ul>

<p>Both W and b are initialized during layer creation and updated each time backward is called.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_units</span><span class="p">,</span> <span class="n">output_units</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        A dense layer is a layer which performs a learned affine transformation:
        f(x) = &lt;W*x&gt; + b
        
        Weights initialised by Xavier initialisation: http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf
        
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="n">self</span><span class="p">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">input_units</span><span class="p">,</span> <span class="n">output_units</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">input_units</span><span class="o">+</span><span class="n">output_units</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">biases</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">output_units</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="nb">input</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Perform an affine transformation:
        f(x) = &lt;W*x&gt; + b
        
        Parameters
        ----------
        input : Tensor of shape [batch_size, num_input_units]
        
        Returns
        ----------
        output: Tensor of shape [batch_size, num_output_units]
        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">weights</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">biases</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>  
        <span class="sh">"""</span><span class="s">
        Parameters
        ----------
        input : Tensor of shape [batch_size, num_input_units]
        
        Returns
        ----------
        grad_output: Tensor of shape [batch_size, num_output_units]
        </span><span class="sh">"""</span>
        <span class="n">grad_input</span> <span class="o">=</span> <span class="n">grad_output</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">.</span><span class="n">T</span>
        
        <span class="n">grad_weights</span> <span class="o">=</span> <span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">grad_output</span><span class="p">)</span>
        <span class="n">grad_biases</span> <span class="o">=</span> <span class="n">grad_output</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  
        <span class="k">assert</span> <span class="n">grad_weights</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">.</span><span class="n">shape</span> <span class="ow">and</span> <span class="n">grad_biases</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">self</span><span class="p">.</span><span class="n">biases</span><span class="p">.</span><span class="n">shape</span>
    
        <span class="n">self</span><span class="p">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weights</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_weights</span>
        <span class="n">self</span><span class="p">.</span><span class="n">biases</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">biases</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_biases</span>
        
        <span class="k">return</span> <span class="n">grad_input</span>
</code></pre></div></div>

<p>Next, some tests:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">l</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>

<span class="k">assert</span> <span class="o">-</span><span class="mf">0.05</span> <span class="o">&lt;</span> <span class="n">l</span><span class="p">.</span><span class="n">weights</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.05</span> <span class="ow">and</span> <span class="mf">1e-3</span> <span class="o">&lt;</span> <span class="n">l</span><span class="p">.</span><span class="n">weights</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">1e-1</span><span class="p">,</span>\
    <span class="sh">"</span><span class="s">The initial weights must have zero mean and small variance. </span><span class="sh">"</span>\
    <span class="sh">"</span><span class="s">If you know what you</span><span class="sh">'</span><span class="s">re doing, remove this assertion.</span><span class="sh">"</span>
<span class="k">assert</span> <span class="o">-</span><span class="mf">0.05</span> <span class="o">&lt;</span> <span class="n">l</span><span class="p">.</span><span class="n">biases</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">,</span> <span class="sh">"</span><span class="s">Biases must be zero mean. Ignore if you have a reason to do otherwise.</span><span class="sh">"</span>

<span class="c1"># To test the outputs, we explicitly set weights with fixed values. DO NOT DO THAT IN ACTUAL NETWORK!
</span><span class="n">l</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="o">*</span><span class="mi">3</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">l</span><span class="p">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="o">*</span><span class="mi">4</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">l</span><span class="p">.</span><span class="n">biases</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">l</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span> <span class="mf">0.07272727</span><span class="p">,</span>  <span class="mf">0.41212121</span><span class="p">,</span>  <span class="mf">0.75151515</span><span class="p">,</span>  <span class="mf">1.09090909</span><span class="p">],</span>
                                          <span class="p">[</span><span class="o">-</span><span class="mf">0.90909091</span><span class="p">,</span>  <span class="mf">0.08484848</span><span class="p">,</span>  <span class="mf">1.07878788</span><span class="p">,</span>  <span class="mf">2.07272727</span><span class="p">]]))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="o">*</span><span class="mi">32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">32</span><span class="p">])</span>
<span class="n">l</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">numeric_grads</span> <span class="o">=</span> <span class="nf">eval_numerical_gradient</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">l</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">sum</span><span class="p">(),</span><span class="n">x</span><span class="p">)</span>
<span class="n">grads</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="nf">backward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">64</span><span class="p">]))</span>

<span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span><span class="n">numeric_grads</span><span class="p">,</span><span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span><span class="n">atol</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="sh">"</span><span class="s">input gradient does not match numeric grad</span><span class="sh">"</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_out_given_wb</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="n">l</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">l</span><span class="p">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="n">l</span><span class="p">.</span><span class="n">biases</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="o">*</span><span class="mi">32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">32</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">l</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">compute_grad_by_params</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="n">l</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">l</span><span class="p">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="n">l</span><span class="p">.</span><span class="n">biases</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="o">*</span><span class="mi">32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">32</span><span class="p">])</span>
    <span class="n">l</span><span class="p">.</span><span class="nf">backward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">64</span><span class="p">])</span> <span class="o">/</span> <span class="mf">10.</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">w</span> <span class="o">-</span> <span class="n">l</span><span class="p">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">b</span> <span class="o">-</span> <span class="n">l</span><span class="p">.</span><span class="n">biases</span>
    
<span class="n">w</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">64</span><span class="p">)</span>

<span class="n">numeric_dw</span> <span class="o">=</span> <span class="nf">eval_numerical_gradient</span><span class="p">(</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="nf">compute_out_given_wb</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">sum</span><span class="p">(),</span><span class="n">w</span> <span class="p">)</span>
<span class="n">numeric_db</span> <span class="o">=</span> <span class="nf">eval_numerical_gradient</span><span class="p">(</span><span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="nf">compute_out_given_wb</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">sum</span><span class="p">(),</span><span class="n">b</span> <span class="p">)</span>
<span class="n">grad_w</span><span class="p">,</span><span class="n">grad_b</span> <span class="o">=</span> <span class="nf">compute_grad_by_params</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">numeric_dw</span><span class="p">,</span><span class="n">grad_w</span><span class="p">,</span><span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span><span class="n">atol</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="sh">"</span><span class="s">weight gradient does not match numeric weight gradient</span><span class="sh">"</span>
<span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">numeric_db</span><span class="p">,</span><span class="n">grad_b</span><span class="p">,</span><span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span><span class="n">atol</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="sh">"</span><span class="s">weight gradient does not match numeric weight gradient</span><span class="sh">"</span>
</code></pre></div></div>

<p>We will optimise the following loss, which is a more numerically stable version of logg loss (courtesy of Coursera advanced ML):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">softmax_crossentropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">reference_answers</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Compute crossentropy from logits[batch,n_classes] and ids of correct answers</span><span class="sh">"""</span>
    <span class="n">logits_for_answers</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">logits</span><span class="p">)),</span><span class="n">reference_answers</span><span class="p">]</span>
    
    <span class="n">xentropy</span> <span class="o">=</span> <span class="o">-</span> <span class="n">logits_for_answers</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">logits</span><span class="p">),</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">xentropy</span>

<span class="k">def</span> <span class="nf">grad_softmax_crossentropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">reference_answers</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Compute crossentropy gradient from logits[batch,n_classes] and ids of correct answers</span><span class="sh">"""</span>
    <span class="n">ones_for_answers</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">ones_for_answers</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">logits</span><span class="p">)),</span><span class="n">reference_answers</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="n">softmax</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">logits</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="nf">return </span><span class="p">(</span><span class="o">-</span> <span class="n">ones_for_answers</span> <span class="o">+</span> <span class="n">softmax</span><span class="p">)</span> <span class="o">/</span> <span class="n">logits</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">500</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span><span class="mi">10</span><span class="p">])</span>
<span class="n">answers</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span><span class="o">%</span><span class="mi">10</span>

<span class="nf">softmax_crossentropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span><span class="n">answers</span><span class="p">)</span>
<span class="n">grads</span> <span class="o">=</span> <span class="nf">grad_softmax_crossentropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span><span class="n">answers</span><span class="p">)</span>
<span class="n">numeric_grads</span> <span class="o">=</span> <span class="nf">eval_numerical_gradient</span><span class="p">(</span><span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="nf">softmax_crossentropy_with_logits</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">answers</span><span class="p">).</span><span class="nf">mean</span><span class="p">(),</span><span class="n">logits</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">numeric_grads</span><span class="p">,</span><span class="n">grads</span><span class="p">,</span><span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span><span class="n">atol</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p>We’ll use the following function to load the mnist dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="n">flatten</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="kn">import</span> <span class="n">keras</span>
    <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span><span class="p">.</span><span class="nf">load_data</span><span class="p">()</span>

    <span class="c1"># normalize x
</span>    <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>

    <span class="c1"># we reserve the last 10000 training examples for validation
</span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:</span><span class="o">-</span><span class="mi">10000</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[</span><span class="o">-</span><span class="mi">10000</span><span class="p">:]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:</span><span class="o">-</span><span class="mi">10000</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="o">-</span><span class="mi">10000</span><span class="p">:]</span>

    <span class="k">if</span> <span class="n">flatten</span><span class="p">:</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">reshape</span><span class="p">([</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">X_val</span> <span class="o">=</span> <span class="n">X_val</span><span class="p">.</span><span class="nf">reshape</span><span class="p">([</span><span class="n">X_val</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="nf">reshape</span><span class="p">([</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="n">flatten</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/thomas.kealy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">network</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">network</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">100</span><span class="p">))</span>
        <span class="n">network</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">ReLU</span><span class="p">())</span>
        <span class="n">network</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">))</span>
        <span class="n">network</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">ReLU</span><span class="p">())</span>
        <span class="n">network</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        comppute activations of all network layers by applying them sequentially.
        Return a list of activations for each layer. 
        Make sure last activation corresponds to network logits.
        </span><span class="sh">"""</span>
        <span class="n">activations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">:</span>
            <span class="n">activations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">layer</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">activations</span><span class="p">)</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">activations</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Compute network predictions.
        </span><span class="sh">"""</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">logits</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Train your network on a given batch of X and y.
        You first need to run forward to get all layer activations.
        Then you can run layer.backward going from last to first layer.
    
        After you called backward for all layers, all Dense layers have already made one gradient step.
        </span><span class="sh">"""</span>
    
        <span class="c1"># Get the layer activations
</span>        <span class="n">layer_activations</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">layer_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">]</span><span class="o">+</span><span class="n">layer_activations</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">layer_activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
        <span class="c1"># Compute the loss and the initial gradient
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="nf">softmax_crossentropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
        <span class="n">loss_grad</span> <span class="o">=</span> <span class="nf">grad_softmax_crossentropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">layer_i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">))[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">[</span><span class="n">layer_i</span><span class="p">]</span>
        
            <span class="n">loss_grad</span> <span class="o">=</span> <span class="n">layer</span><span class="p">.</span><span class="nf">backward</span><span class="p">(</span><span class="n">layer_inputs</span><span class="p">[</span><span class="n">layer_i</span><span class="p">],</span><span class="n">loss_grad</span><span class="p">)</span> 
            
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>

<p>Finally, we can train our nework!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">trange</span>
<span class="k">def</span> <span class="nf">iterate_minibatches</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">start_idx</span> <span class="ow">in</span> <span class="nf">trange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">-</span> <span class="n">batchsize</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">excerpt</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">batchsize</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">excerpt</span> <span class="o">=</span> <span class="nf">slice</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batchsize</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">inputs</span><span class="p">[</span><span class="n">excerpt</span><span class="p">],</span> <span class="n">targets</span><span class="p">[</span><span class="n">excerpt</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">network</span> <span class="o">=</span> <span class="nc">Network</span><span class="p">()</span>
<span class="n">train_log</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_log</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>

    <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span> <span class="ow">in</span> <span class="nf">iterate_minibatches</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">batchsize</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="n">network</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">)</span>
    
    <span class="n">train_log</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">network</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">==</span><span class="n">y_train</span><span class="p">))</span>
    <span class="n">val_log</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">network</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span><span class="o">==</span><span class="n">y_val</span><span class="p">))</span>
    
    <span class="nf">clear_output</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Epoch</span><span class="sh">"</span><span class="p">,</span><span class="n">epoch</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Train accuracy:</span><span class="sh">"</span><span class="p">,</span><span class="n">train_log</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Val accuracy:</span><span class="sh">"</span><span class="p">,</span><span class="n">val_log</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">train_log</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">train accuracy</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">val_log</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">val accuracy</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">'</span><span class="s">best</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 24
Train accuracy: 1.0
Val accuracy: 0.9819
</code></pre></div></div>

<p><img src="2021-06-21-Neural-Netwroks-From-Scratch_files/2021-06-21-Neural-Netwroks-From-Scratch_26_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/06/07/bayesian-structural-time-series-in-pystan.html"><h2 class="larger">Bayesian Structural Time Series In Pystan</h2></a>
          <br><span class="smaller">June 7, 2021</span>  <br/>
          <div><p>Let \(y_t\) denote observation \(t\) in a real-valued time series. A structural time series model can be described by a pair of equations relating yt to a vector of latent state variables $u_t$</p>

\[y_t = Z^T_tu_{t} + \varepsilon_t\]

\[u_T = Tu_{t_1} + R\eta_t\]

<p>Where \( \varepsilon_t \sim N\left(0, H_t\right) \) and \( \eta_t \sim N\left(0, Q_t\right) \).</p>

<p>One usefuel extension of thsi model is the ‘basic’ structural time series, which can be described in the following equations:</p>

\[y_t = u_{t} + \tau_t + \beta^T\textbf{x} + \varepsilon_t\]

\[u_T = u_{t_1} + \delta_{t-1} + \eta_t\]

\[\delta_t = \delta_{t-1} + \nu_t\]

\[\tau_t = -\sum_{s=1}^{S-1} \tau_{t-s} + w_t\]

<p>We’ll model this in sections, firsly by excluding the seasonal component.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pystan</span>
<span class="kn">import</span> <span class="n">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">'</span><span class="s">ggplot</span><span class="sh">'</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">stan_code</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">data {
  int &lt;lower=0&gt; T;
  vector[T] x;
  vector[T] y;
}

parameters {
  vector[T] u_err; //Slope innovation
  vector[T] v_err; //Level innovation
  real beta;
  real &lt;lower=0&gt; s_obs;
  real &lt;lower=0&gt; s_slope;
  real &lt;lower=0&gt; s_level;
}

transformed parameters {
  vector[T] u; //Level
  vector[T] v; //Slope
  u[1] = u_err[1];
  v[1] = v_err[1];
  for (t in 2:T) {
    u[t] = u[t-1] + v[t-1] + s_level * u_err[t];
    v[t] = v[t-1] + s_slope * v_err[t];
  }
}

model {
  u_err ~ normal(0,1);
  v_err ~ normal(0,1);
  y ~ normal (u + beta*x, s_obs);
}</span><span class="sh">"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">unemployment.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">unemployment.office</span><span class="sh">'</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x10ab7c048&gt;
</code></pre></div></div>

<p><img src="2021-06-07-bayesian-structural-time-series-in-pystan_files/2021-06-07-bayesian-structural-time-series-in-pystan_3_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_feed</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">unemployment.office</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">)),</span> <span class="sh">'</span><span class="s">T</span><span class="sh">'</span><span class="p">:</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]}</span>
<span class="n">sm</span> <span class="o">=</span> <span class="n">pystan</span><span class="p">.</span><span class="nc">StanModel</span><span class="p">(</span><span class="n">model_code</span><span class="o">=</span><span class="n">stan_code</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">sampling</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_feed</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_a216d1830c917dccb932a956782a2c63 NOW.
/Users/thomas.kealy/anaconda3/lib/python3.7/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  elif np.issubdtype(np.asarray(v).dtype, float):
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">mpl</span><span class="p">.</span><span class="nf">rc_context</span><span class="p">():</span>
    <span class="n">mpl</span><span class="p">.</span><span class="nf">rc</span><span class="p">(</span><span class="sh">'</span><span class="s">figure</span><span class="sh">'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">fit</span><span class="p">.</span><span class="nf">plot</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="2021-06-07-bayesian-structural-time-series-in-pystan_files/2021-06-07-bayesian-structural-time-series-in-pystan_5_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span> <span class="o">=</span> <span class="n">fit</span><span class="p">.</span><span class="nf">extract</span><span class="p">(</span><span class="n">permuted</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="sh">'</span><span class="s">u</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="sh">'</span><span class="s">v</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">v</span>
<span class="n">data</span><span class="p">[[</span><span class="sh">'</span><span class="s">unemployment.office</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">]].</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a25b3e9b0&gt;
</code></pre></div></div>

<p><img src="2021-06-07-bayesian-structural-time-series-in-pystan_files/2021-06-07-bayesian-structural-time-series-in-pystan_7_1.png" alt="png" /></p>

<p>The fit looks ok, but it can definately be improved by adding a seasonal component.</p>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/05/05/gradient-free-gradient-descent.html"><h2 class="larger">Gradient Free Gradient Descent</h2></a>
          <br><span class="smaller">May 5, 2021</span>  <br/>
          <div><h1 id="gradient-descent-without-gradients">Gradient Descent Without Gradients</h1>

<p>In the last post I introduced Gradient Descent, and used it to a simple linear regression in 1 dimension. The function that did most of the work was:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">num_iters</span><span class="o">=</span><span class="mi">250</span><span class="p">):</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">theta</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span>
    <span class="k">yield</span> <span class="n">theta</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">yhat</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">theta</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span>
        <span class="n">yhatt</span> <span class="o">=</span> <span class="n">yhat</span><span class="p">.</span><span class="n">T</span>
        <span class="n">nabla</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">yhatt</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="nf">assert</span><span class="p">(</span><span class="n">nabla</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">theta</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">theta</span> <span class="o">+=</span>  <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">learning_rate</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">nabla</span>
        <span class="k">yield</span> <span class="n">theta</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">yhat</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div></div>

<p>However, this function has a drawback - it only works for linear regression. In this post we’ll modify the function to take other losses and perform gradient descent automatically. Let’s first generate some toy data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">autograd.numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span> 
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="p">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="sh">'</span><span class="s">retina</span><span class="sh">'</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">([</span><span class="sh">'</span><span class="s">seaborn-colorblind</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">seaborn-darkgrid</span><span class="sh">'</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">make_blobs</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.1</span>
    <span class="n">samples_per_class</span> <span class="o">=</span> <span class="n">num_samples</span> <span class="o">//</span> <span class="n">num_classes</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="n">class_samples</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="p">(</span><span class="n">samples_per_class</span><span class="p">,</span> <span class="n">num_features</span><span class="p">))</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">samples_per_class</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">samples_per_class</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_samples</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">samples_per_class</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">samples_per_class</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
    

<span class="k">def</span> <span class="nf">plot_clusters</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">colours</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">g</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="n">x_class</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">temp</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">x_class</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_class</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colours</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">NUM_FEATURES</span><span class="o">=</span><span class="mi">50</span>
<span class="n">NUM_CLASSES</span><span class="o">=</span><span class="mi">2</span>
<span class="n">NUM_SAMPLES</span><span class="o">=</span><span class="mi">1000</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">=</span> <span class="nf">make_blobs</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">NUM_SAMPLES</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="n">NUM_FEATURES</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">)</span>
<span class="nf">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="2021-05-05-gradient-free-gradient-descent_files/2021-05-05-gradient-free-gradient-descent_4_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-0.05461888,  0.93787102, -0.09551936, ...,  0.02657511,
         0.72509201,  0.68530672],
       [-0.09366208,  0.7994963 ,  0.008594  , ...,  0.12660328,
         0.60329672,  0.66772192],
       [ 0.13367689,  0.81014452, -0.10304008, ...,  0.15666234,
         0.71245837,  0.57504779],
       ..., 
       [ 0.9828324 ,  0.82414756,  0.55084061, ...,  0.23759356,
         1.06799085,  0.56271078],
       [ 0.77171086,  0.93970304,  0.37411522, ...,  0.04376771,
         0.95470468,  0.43622007],
       [ 0.8846701 ,  0.89806374,  0.35203692, ...,  0.09546763,
         1.09566046,  0.5202908 ]])
</code></pre></div></div>

<p>We’ll predict the class of each point using softmax (multinomial logistic) regression. The model has a matrix $ W $ of weights, which measures for each feature how likely that feature is to be in a particular. It is of size $ \mathrm{n_{features}} \times \mathrm{n_{classes}} $. The goal of softmax regression is to learn such a matrix. Given a matrix of weights, $ W $, and matrix of points, $ X $, it predicts the probability od each class given the samples</p>

\[p\left( y_i | x_i ; w \right) = \frac{e^{w_j^T x_i}}{\sum_j e^{w_j^T x_i}}\]

<p>This prediction is encapsulated in the following function:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">prob</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
</code></pre></div></div>

<p>To get a feel we’ll make a random guess:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">NUM_FEATURES</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="2021-05-05-gradient-free-gradient-descent_files/2021-05-05-gradient-free-gradient-descent_10_0.png" alt="png" /></p>

<p>As you can see, that looks nothing like the real clusters!</p>

<p>Logistic regression minimises the following loss function:</p>

\[J\left(w\right) = y * p\left( y_i | x_i ; w \right) + (1-y) * (1 - p\left( y_i | x_i ; w \right))\]

<p>There is a mathematical justification for why this is the right loss to use, but heuristically, this loss minimises the probability error between the predicition classes and the true classes.</p>

<p>In python, the loss can be written:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="n">label_probabilities</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">*</span> <span class="n">targets</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">label_probabilities</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">loss</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4750.573533547572
</code></pre></div></div>

<p>We’re now in a position to do gradient descent!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">autograd</span> <span class="kn">import</span> <span class="n">grad</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="nf">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent_auto</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">num_iters</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
    <span class="kn">from</span> <span class="n">autograd</span> <span class="kn">import</span> <span class="n">grad</span>
    <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="nf">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    <span class="k">yield</span> <span class="n">weights</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
        <span class="n">nabla</span> <span class="o">=</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">nabla</span>
        <span class="k">yield</span> <span class="n">weights</span><span class="p">,</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weights</span> <span class="o">=</span> <span class="nf">gradient_descent_auto</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="n">costs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">w</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictions</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="2021-05-05-gradient-free-gradient-descent_files/2021-05-05-gradient-free-gradient-descent_19_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x11e28a9b0&gt;]
</code></pre></div></div>

<p><img src="2021-05-05-gradient-free-gradient-descent_files/2021-05-05-gradient-free-gradient-descent_20_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/04/08/Model-Selection-wiht-GAMs.html"><h2 class="larger">Model Selection Wiht Gams</h2></a>
          <br><span class="smaller">April 8, 2021</span>  <br/>
          <div><p>The last part of moddeling with (univariate spline) GAMs is choosing the smoothing parameter \( \lambda \). This post will elaborate on this, using the <code class="language-plaintext highlighter-rouge">scikit-learn</code> <code class="language-plaintext highlighter-rouge">GriddSearchCV</code> functionality to do this. We’ll use <code class="language-plaintext highlighter-rouge">pyGAM</code> to do the heavy lifting, and we’ll use the same data as the last post</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">patsy</span>
<span class="kn">import</span> <span class="n">scipy</span> <span class="k">as</span> <span class="n">sp</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="n">statsmodels</span> <span class="kn">import</span> <span class="n">api</span> <span class="k">as</span> <span class="n">sm</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">mcycle.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">Unnamed: 0</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">min_time</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">.</span><span class="nf">min</span><span class="p">()</span>
<span class="n">max_time</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">blue</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">accel</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">blue</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">time</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Acceleration</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0,0.5,'Acceleration')
</code></pre></div></div>

<p><img src="2021-04-08-Model-Selection-wiht-GAMs_files/2021-04-08-Model-Selection-wiht-GAMs_1_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">splines</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">R</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="nf">return </span><span class="p">((</span><span class="n">z</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">12</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">12</span><span class="p">)</span> <span class="o">/</span> <span class="mi">4</span> <span class="o">-</span> <span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">4</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">7</span> <span class="o">/</span> <span class="mi">240</span><span class="p">)</span> <span class="o">/</span> <span class="mi">24</span>

    <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">frompyfunc</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">R_</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">R</span><span class="p">.</span><span class="nf">outer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">knots</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrices</span><span class="p">(</span><span class="sh">'</span><span class="s">accel ~ times + R_(times)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>

    <span class="n">knots</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">.</span><span class="nf">quantile</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">q</span><span class="p">))</span>
    
<span class="k">def</span> <span class="nf">GAM</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>    

    <span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">q</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">q</span> <span class="o">+</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">S</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="nc">R_</span><span class="p">(</span><span class="n">knots</span><span class="p">)</span>

    <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
    <span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">real_if_close</span><span class="p">(</span><span class="n">sp</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">sqrtm</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="mi">2</span><span class="p">:,</span> <span class="mi">2</span><span class="p">:]),</span> <span class="n">tol</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="mi">8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="n">gamma</span><span class="p">):</span>
        <span class="c1"># build the augmented matrices
</span>        <span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">q</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))))</span>
        <span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">lambda_</span><span class="p">)</span> <span class="o">*</span> <span class="n">B</span><span class="p">))</span>
    
        <span class="k">return</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span> <span class="n">X_</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">min_time</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">.</span><span class="nf">min</span><span class="p">()</span>
<span class="n">max_time</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span>

<span class="n">plot_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">min_time</span><span class="p">,</span> <span class="n">max_time</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plot_X</span> <span class="o">=</span> <span class="n">patsy</span><span class="p">.</span><span class="nf">dmatrix</span><span class="p">(</span><span class="sh">'</span><span class="s">times + R_(times)</span><span class="sh">'</span><span class="p">,</span> <span class="p">{</span><span class="sh">'</span><span class="s">times</span><span class="sh">'</span><span class="p">:</span> <span class="n">plot_x</span><span class="p">})</span>

<span class="n">results</span> <span class="o">=</span> <span class="nc">GAM</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">blue</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">times</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">accel</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">blue</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">plot_x</span><span class="p">,</span> <span class="n">results</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">plot_X</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">time</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">accel</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">$\lambda = {}$</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

~/anaconda3/lib/python3.6/site-packages/patsy/compat.py in call_and_wrap_exc(msg, origin, f, *args, **kwargs)
     35     try:
---&gt; 36         return f(*args, **kwargs)
     37     except Exception as e:


~/anaconda3/lib/python3.6/site-packages/patsy/eval.py in eval(self, expr, source_name, inner_namespace)
    165         return eval(code, {}, VarLookupDict([inner_namespace]
--&gt; 166                                             + self._namespaces))
    167 


&lt;string&gt; in &lt;module&gt;()


NameError: name 'R_' is not defined


The above exception was the direct cause of the following exception:


PatsyError                                Traceback (most recent call last)

&lt;ipython-input-3-9eb1425fd693&gt; in &lt;module&gt;()
      3 
      4 plot_x = np.linspace(min_time, max_time, 100)
----&gt; 5 plot_X = patsy.dmatrix('times + R_(times)', {'times': plot_x})
      6 
      7 results = GAM(df)


~/anaconda3/lib/python3.6/site-packages/patsy/highlevel.py in dmatrix(formula_like, data, eval_env, NA_action, return_type)
    289     eval_env = EvalEnvironment.capture(eval_env, reference=1)
    290     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,
--&gt; 291                                       NA_action, return_type)
    292     if lhs.shape[1] != 0:
    293         raise PatsyError("encountered outcome variables for a model "


~/anaconda3/lib/python3.6/site-packages/patsy/highlevel.py in _do_highlevel_design(formula_like, data, eval_env, NA_action, return_type)
    163         return iter([data])
    164     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,
--&gt; 165                                       NA_action)
    166     if design_infos is not None:
    167         return build_design_matrices(design_infos, data,


~/anaconda3/lib/python3.6/site-packages/patsy/highlevel.py in _try_incr_builders(formula_like, data_iter_maker, eval_env, NA_action)
     68                                       data_iter_maker,
     69                                       eval_env,
---&gt; 70                                       NA_action)
     71     else:
     72         return None


~/anaconda3/lib/python3.6/site-packages/patsy/build.py in design_matrix_builders(termlists, data_iter_maker, eval_env, NA_action)
    694                                                    factor_states,
    695                                                    data_iter_maker,
--&gt; 696                                                    NA_action)
    697     # Now we need the factor infos, which encapsulate the knowledge of
    698     # how to turn any given factor into a chunk of data:


~/anaconda3/lib/python3.6/site-packages/patsy/build.py in _examine_factor_types(factors, factor_states, data_iter_maker, NA_action)
    441     for data in data_iter_maker():
    442         for factor in list(examine_needed):
--&gt; 443             value = factor.eval(factor_states[factor], data)
    444             if factor in cat_sniffers or guess_categorical(value):
    445                 if factor not in cat_sniffers:


~/anaconda3/lib/python3.6/site-packages/patsy/eval.py in eval(self, memorize_state, data)
    564         return self._eval(memorize_state["eval_code"],
    565                           memorize_state,
--&gt; 566                           data)
    567 
    568     __getstate__ = no_pickling


~/anaconda3/lib/python3.6/site-packages/patsy/eval.py in _eval(self, code, memorize_state, data)
    549                                  memorize_state["eval_env"].eval,
    550                                  code,
--&gt; 551                                  inner_namespace=inner_namespace)
    552 
    553     def memorize_chunk(self, state, which_pass, data):


~/anaconda3/lib/python3.6/site-packages/patsy/compat.py in call_and_wrap_exc(msg, origin, f, *args, **kwargs)
     41                                  origin)
     42             # Use 'exec' to hide this syntax from the Python 2 parser:
---&gt; 43             exec("raise new_exc from e")
     44         else:
     45             # In python 2, we just let the original exception escape -- better


~/anaconda3/lib/python3.6/site-packages/patsy/compat.py in &lt;module&gt;()


PatsyError: Error evaluating factor: NameError: name 'R_' is not defined
    times + R_(times)
            ^^^^^^^^^
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/04/01/ames-iowa.html"><h2 class="larger">Ames Iowa</h2></a>
          <br><span class="smaller">April 1, 2021</span>  <br/>
          <div><h1 id="pipelines-and-pandas">Pipelines and Pandas</h1>

<p>This is a short post about how to use Scikit-Learn Pipelines so that you have ‘Pandas in, pandas out’. I’ll build a small data pipeline on the Ames Iowa housing dataset. The first thing is to import the dataset, and inspect it! The data has 82 columns which include 23 nominal, 23 ordinal, 14 discrete, and 20 continuous variables (and 2 additional observation identifiers).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ames</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">ames.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ames</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Order</th>
      <th>PID</th>
      <th>MS.SubClass</th>
      <th>MS.Zoning</th>
      <th>Lot.Frontage</th>
      <th>Lot.Area</th>
      <th>Street</th>
      <th>Alley</th>
      <th>Lot.Shape</th>
      <th>Land.Contour</th>
      <th>...</th>
      <th>Pool.Area</th>
      <th>Pool.QC</th>
      <th>Fence</th>
      <th>Misc.Feature</th>
      <th>Misc.Val</th>
      <th>Mo.Sold</th>
      <th>Yr.Sold</th>
      <th>Sale.Type</th>
      <th>Sale.Condition</th>
      <th>SalePrice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>526301100</td>
      <td>20</td>
      <td>RL</td>
      <td>141.0</td>
      <td>31770</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>IR1</td>
      <td>Lvl</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>5</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>215000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>526350040</td>
      <td>20</td>
      <td>RH</td>
      <td>80.0</td>
      <td>11622</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>Reg</td>
      <td>Lvl</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>MnPrv</td>
      <td>NaN</td>
      <td>0</td>
      <td>6</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>105000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>526351010</td>
      <td>20</td>
      <td>RL</td>
      <td>81.0</td>
      <td>14267</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>IR1</td>
      <td>Lvl</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Gar2</td>
      <td>12500</td>
      <td>6</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>172000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>526353030</td>
      <td>20</td>
      <td>RL</td>
      <td>93.0</td>
      <td>11160</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>Reg</td>
      <td>Lvl</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>4</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>244000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>527105010</td>
      <td>60</td>
      <td>RL</td>
      <td>74.0</td>
      <td>13830</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>IR1</td>
      <td>Lvl</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>MnPrv</td>
      <td>NaN</td>
      <td>0</td>
      <td>3</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>189900</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>527105030</td>
      <td>60</td>
      <td>RL</td>
      <td>78.0</td>
      <td>9978</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>IR1</td>
      <td>Lvl</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>6</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>195500</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>527127150</td>
      <td>120</td>
      <td>RL</td>
      <td>41.0</td>
      <td>4920</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>Reg</td>
      <td>Lvl</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>4</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>213500</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>527145080</td>
      <td>120</td>
      <td>RL</td>
      <td>43.0</td>
      <td>5005</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>IR1</td>
      <td>HLS</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>1</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>191500</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>527146030</td>
      <td>120</td>
      <td>RL</td>
      <td>39.0</td>
      <td>5389</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>IR1</td>
      <td>Lvl</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>3</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>236500</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>527162130</td>
      <td>60</td>
      <td>RL</td>
      <td>60.0</td>
      <td>7500</td>
      <td>Pave</td>
      <td>NaN</td>
      <td>Reg</td>
      <td>Lvl</td>
      <td>...</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>6</td>
      <td>2010</td>
      <td>WD</td>
      <td>Normal</td>
      <td>189000</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 82 columns</p>
</div>

<p>It’s always a good idea to set an index on a DataFrame if you have one. In this case, the <code class="language-plaintext highlighter-rouge">PID</code> column is a unique identifier.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ames</span> <span class="o">=</span> <span class="n">ames</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">PID</span><span class="sh">'</span><span class="p">).</span><span class="nf">copy</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ames</span><span class="p">.</span><span class="nf">describe</span><span class="p">().</span><span class="n">T</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Order</th>
      <td>2930.0</td>
      <td>1465.500000</td>
      <td>845.962470</td>
      <td>1.0</td>
      <td>733.25</td>
      <td>1465.5</td>
      <td>2197.75</td>
      <td>2930.0</td>
    </tr>
    <tr>
      <th>MS.SubClass</th>
      <td>2930.0</td>
      <td>57.387372</td>
      <td>42.638025</td>
      <td>20.0</td>
      <td>20.00</td>
      <td>50.0</td>
      <td>70.00</td>
      <td>190.0</td>
    </tr>
    <tr>
      <th>Lot.Frontage</th>
      <td>2440.0</td>
      <td>69.224590</td>
      <td>23.365335</td>
      <td>21.0</td>
      <td>58.00</td>
      <td>68.0</td>
      <td>80.00</td>
      <td>313.0</td>
    </tr>
    <tr>
      <th>Lot.Area</th>
      <td>2930.0</td>
      <td>10147.921843</td>
      <td>7880.017759</td>
      <td>1300.0</td>
      <td>7440.25</td>
      <td>9436.5</td>
      <td>11555.25</td>
      <td>215245.0</td>
    </tr>
    <tr>
      <th>Overall.Qual</th>
      <td>2930.0</td>
      <td>6.094881</td>
      <td>1.411026</td>
      <td>1.0</td>
      <td>5.00</td>
      <td>6.0</td>
      <td>7.00</td>
      <td>10.0</td>
    </tr>
    <tr>
      <th>Overall.Cond</th>
      <td>2930.0</td>
      <td>5.563140</td>
      <td>1.111537</td>
      <td>1.0</td>
      <td>5.00</td>
      <td>5.0</td>
      <td>6.00</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>Year.Built</th>
      <td>2930.0</td>
      <td>1971.356314</td>
      <td>30.245361</td>
      <td>1872.0</td>
      <td>1954.00</td>
      <td>1973.0</td>
      <td>2001.00</td>
      <td>2010.0</td>
    </tr>
    <tr>
      <th>Year.Remod.Add</th>
      <td>2930.0</td>
      <td>1984.266553</td>
      <td>20.860286</td>
      <td>1950.0</td>
      <td>1965.00</td>
      <td>1993.0</td>
      <td>2004.00</td>
      <td>2010.0</td>
    </tr>
    <tr>
      <th>Mas.Vnr.Area</th>
      <td>2907.0</td>
      <td>101.896801</td>
      <td>179.112611</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>164.00</td>
      <td>1600.0</td>
    </tr>
    <tr>
      <th>BsmtFin.SF.1</th>
      <td>2929.0</td>
      <td>442.629566</td>
      <td>455.590839</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>370.0</td>
      <td>734.00</td>
      <td>5644.0</td>
    </tr>
    <tr>
      <th>BsmtFin.SF.2</th>
      <td>2929.0</td>
      <td>49.722431</td>
      <td>169.168476</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>1526.0</td>
    </tr>
    <tr>
      <th>Bsmt.Unf.SF</th>
      <td>2929.0</td>
      <td>559.262547</td>
      <td>439.494153</td>
      <td>0.0</td>
      <td>219.00</td>
      <td>466.0</td>
      <td>802.00</td>
      <td>2336.0</td>
    </tr>
    <tr>
      <th>Total.Bsmt.SF</th>
      <td>2929.0</td>
      <td>1051.614544</td>
      <td>440.615067</td>
      <td>0.0</td>
      <td>793.00</td>
      <td>990.0</td>
      <td>1302.00</td>
      <td>6110.0</td>
    </tr>
    <tr>
      <th>X1st.Flr.SF</th>
      <td>2930.0</td>
      <td>1159.557679</td>
      <td>391.890885</td>
      <td>334.0</td>
      <td>876.25</td>
      <td>1084.0</td>
      <td>1384.00</td>
      <td>5095.0</td>
    </tr>
    <tr>
      <th>X2nd.Flr.SF</th>
      <td>2930.0</td>
      <td>335.455973</td>
      <td>428.395715</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>703.75</td>
      <td>2065.0</td>
    </tr>
    <tr>
      <th>Low.Qual.Fin.SF</th>
      <td>2930.0</td>
      <td>4.676792</td>
      <td>46.310510</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>1064.0</td>
    </tr>
    <tr>
      <th>Gr.Liv.Area</th>
      <td>2930.0</td>
      <td>1499.690444</td>
      <td>505.508887</td>
      <td>334.0</td>
      <td>1126.00</td>
      <td>1442.0</td>
      <td>1742.75</td>
      <td>5642.0</td>
    </tr>
    <tr>
      <th>Bsmt.Full.Bath</th>
      <td>2928.0</td>
      <td>0.431352</td>
      <td>0.524820</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>1.00</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Bsmt.Half.Bath</th>
      <td>2928.0</td>
      <td>0.061134</td>
      <td>0.245254</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>Full.Bath</th>
      <td>2930.0</td>
      <td>1.566553</td>
      <td>0.552941</td>
      <td>0.0</td>
      <td>1.00</td>
      <td>2.0</td>
      <td>2.00</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>Half.Bath</th>
      <td>2930.0</td>
      <td>0.379522</td>
      <td>0.502629</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>1.00</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>Bedroom.AbvGr</th>
      <td>2930.0</td>
      <td>2.854266</td>
      <td>0.827731</td>
      <td>0.0</td>
      <td>2.00</td>
      <td>3.0</td>
      <td>3.00</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>Kitchen.AbvGr</th>
      <td>2930.0</td>
      <td>1.044369</td>
      <td>0.214076</td>
      <td>0.0</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>1.00</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>TotRms.AbvGrd</th>
      <td>2930.0</td>
      <td>6.443003</td>
      <td>1.572964</td>
      <td>2.0</td>
      <td>5.00</td>
      <td>6.0</td>
      <td>7.00</td>
      <td>15.0</td>
    </tr>
    <tr>
      <th>Fireplaces</th>
      <td>2930.0</td>
      <td>0.599317</td>
      <td>0.647921</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>1.00</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>Garage.Yr.Blt</th>
      <td>2771.0</td>
      <td>1978.132443</td>
      <td>25.528411</td>
      <td>1895.0</td>
      <td>1960.00</td>
      <td>1979.0</td>
      <td>2002.00</td>
      <td>2207.0</td>
    </tr>
    <tr>
      <th>Garage.Cars</th>
      <td>2929.0</td>
      <td>1.766815</td>
      <td>0.760566</td>
      <td>0.0</td>
      <td>1.00</td>
      <td>2.0</td>
      <td>2.00</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>Garage.Area</th>
      <td>2929.0</td>
      <td>472.819734</td>
      <td>215.046549</td>
      <td>0.0</td>
      <td>320.00</td>
      <td>480.0</td>
      <td>576.00</td>
      <td>1488.0</td>
    </tr>
    <tr>
      <th>Wood.Deck.SF</th>
      <td>2930.0</td>
      <td>93.751877</td>
      <td>126.361562</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>168.00</td>
      <td>1424.0</td>
    </tr>
    <tr>
      <th>Open.Porch.SF</th>
      <td>2930.0</td>
      <td>47.533447</td>
      <td>67.483400</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>27.0</td>
      <td>70.00</td>
      <td>742.0</td>
    </tr>
    <tr>
      <th>Enclosed.Porch</th>
      <td>2930.0</td>
      <td>23.011604</td>
      <td>64.139059</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>1012.0</td>
    </tr>
    <tr>
      <th>X3Ssn.Porch</th>
      <td>2930.0</td>
      <td>2.592491</td>
      <td>25.141331</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>508.0</td>
    </tr>
    <tr>
      <th>Screen.Porch</th>
      <td>2930.0</td>
      <td>16.002048</td>
      <td>56.087370</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>576.0</td>
    </tr>
    <tr>
      <th>Pool.Area</th>
      <td>2930.0</td>
      <td>2.243345</td>
      <td>35.597181</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>800.0</td>
    </tr>
    <tr>
      <th>Misc.Val</th>
      <td>2930.0</td>
      <td>50.635154</td>
      <td>566.344288</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>17000.0</td>
    </tr>
    <tr>
      <th>Mo.Sold</th>
      <td>2930.0</td>
      <td>6.216041</td>
      <td>2.714492</td>
      <td>1.0</td>
      <td>4.00</td>
      <td>6.0</td>
      <td>8.00</td>
      <td>12.0</td>
    </tr>
    <tr>
      <th>Yr.Sold</th>
      <td>2930.0</td>
      <td>2007.790444</td>
      <td>1.316613</td>
      <td>2006.0</td>
      <td>2007.00</td>
      <td>2008.0</td>
      <td>2009.00</td>
      <td>2010.0</td>
    </tr>
    <tr>
      <th>SalePrice</th>
      <td>2930.0</td>
      <td>180796.060068</td>
      <td>79886.692357</td>
      <td>12789.0</td>
      <td>129500.00</td>
      <td>160000.0</td>
      <td>213500.00</td>
      <td>755000.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>The main comment is that there’s a lof of missing data, and that some columns should be dropped entirely (in particular Alley, Pool QC, Fence, Misc Feature, Fireplace QC) - or the dataset documentation needs to be checked to see that N/A isn’t a default category in these cases. There’s also a mixture of categorical and numerical features, which is a little tricky to handle. Luckily sklearn has the <code class="language-plaintext highlighter-rouge">FeatureUnion</code> and <code class="language-plaintext highlighter-rouge">Pipeline</code> objects to help us.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ames</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Order                0
MS.SubClass          0
MS.Zoning            0
Lot.Frontage       490
Lot.Area             0
Street               0
Alley             2732
Lot.Shape            0
Land.Contour         0
Utilities            0
Lot.Config           0
Land.Slope           0
Neighborhood         0
Condition.1          0
Condition.2          0
Bldg.Type            0
House.Style          0
Overall.Qual         0
Overall.Cond         0
Year.Built           0
Year.Remod.Add       0
Roof.Style           0
Roof.Matl            0
Exterior.1st         0
Exterior.2nd         0
Mas.Vnr.Type        23
Mas.Vnr.Area        23
Exter.Qual           0
Exter.Cond           0
Foundation           0
                  ... 
Bedroom.AbvGr        0
Kitchen.AbvGr        0
Kitchen.Qual         0
TotRms.AbvGrd        0
Functional           0
Fireplaces           0
Fireplace.Qu      1422
Garage.Type        157
Garage.Yr.Blt      159
Garage.Finish      159
Garage.Cars          1
Garage.Area          1
Garage.Qual        159
Garage.Cond        159
Paved.Drive          0
Wood.Deck.SF         0
Open.Porch.SF        0
Enclosed.Porch       0
X3Ssn.Porch          0
Screen.Porch         0
Pool.Area            0
Pool.QC           2917
Fence             2358
Misc.Feature      2824
Misc.Val             0
Mo.Sold              0
Yr.Sold              0
Sale.Type            0
Sale.Condition       0
SalePrice            0
Length: 81, dtype: int64
</code></pre></div></div>

<p>First of all, let’s build a transformer which drops the columns we suggest. A sklearn compatible transformer is a class which has to have two methods <code class="language-plaintext highlighter-rouge">fit</code> (which returns <code class="language-plaintext highlighter-rouge">self</code>), and <code class="language-plaintext highlighter-rouge">transform</code> (which can return whatever you want). It’s a good idea to inherit from <code class="language-plaintext highlighter-rouge">sklearn.base.TransformerMixin</code> and <code class="language-plaintext highlighter-rouge">sklearn.base.BaseEstimator</code>. The general pattern of a Transformer is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>

<span class="k">class</span> <span class="nc">ExampleTransformer</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span>
    
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">do_something_to</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</code></pre></div></div>

<p>These are actually quite simple, and can be quite flexible. Later on, we might see a transformer that uses the <code class="language-plaintext highlighter-rouge">fit</code> method. Anyway, here’s a column dropper.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">FeatureUnion</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LarsCV</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span>  <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_squared_log_error</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ColumnDropper</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">
    Transformer to drop a list of cols
    </span><span class="sh">'''</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">drop_cols</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">_drop_cols</span> <span class="o">=</span> <span class="n">drop_cols</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span>
    
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_drop_cols</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">ames</span><span class="p">[</span><span class="sh">'</span><span class="s">SalePrice</span><span class="sh">'</span><span class="p">].</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">ames</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">SalePrice</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">X</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['Order', 'MS.SubClass', 'MS.Zoning', 'Lot.Frontage', 'Lot.Area',
       'Street', 'Alley', 'Lot.Shape', 'Land.Contour', 'Utilities',
       'Lot.Config', 'Land.Slope', 'Neighborhood', 'Condition.1',
       'Condition.2', 'Bldg.Type', 'House.Style', 'Overall.Qual',
       'Overall.Cond', 'Year.Built', 'Year.Remod.Add', 'Roof.Style',
       'Roof.Matl', 'Exterior.1st', 'Exterior.2nd', 'Mas.Vnr.Type',
       'Mas.Vnr.Area', 'Exter.Qual', 'Exter.Cond', 'Foundation', 'Bsmt.Qual',
       'Bsmt.Cond', 'Bsmt.Exposure', 'BsmtFin.Type.1', 'BsmtFin.SF.1',
       'BsmtFin.Type.2', 'BsmtFin.SF.2', 'Bsmt.Unf.SF', 'Total.Bsmt.SF',
       'Heating', 'Heating.QC', 'Central.Air', 'Electrical', 'X1st.Flr.SF',
       'X2nd.Flr.SF', 'Low.Qual.Fin.SF', 'Gr.Liv.Area', 'Bsmt.Full.Bath',
       'Bsmt.Half.Bath', 'Full.Bath', 'Half.Bath', 'Bedroom.AbvGr',
       'Kitchen.AbvGr', 'Kitchen.Qual', 'TotRms.AbvGrd', 'Functional',
       'Fireplaces', 'Fireplace.Qu', 'Garage.Type', 'Garage.Yr.Blt',
       'Garage.Finish', 'Garage.Cars', 'Garage.Area', 'Garage.Qual',
       'Garage.Cond', 'Paved.Drive', 'Wood.Deck.SF', 'Open.Porch.SF',
       'Enclosed.Porch', 'X3Ssn.Porch', 'Screen.Porch', 'Pool.Area', 'Pool.QC',
       'Fence', 'Misc.Feature', 'Misc.Val', 'Mo.Sold', 'Yr.Sold', 'Sale.Type',
       'Sale.Condition'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipe</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([(</span><span class="sh">'</span><span class="s">dropper</span><span class="sh">'</span><span class="p">,</span> <span class="nc">ColumnDropper</span><span class="p">([</span><span class="sh">'</span><span class="s">Alley</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Pool.QC</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Fence</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Misc.Feature</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Fireplace.Qu</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Order</span><span class="sh">'</span><span class="p">]))])</span>
<span class="n">X_trans</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_trans</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['MS.SubClass', 'MS.Zoning', 'Lot.Frontage', 'Lot.Area', 'Street',
       'Lot.Shape', 'Land.Contour', 'Utilities', 'Lot.Config', 'Land.Slope',
       'Neighborhood', 'Condition.1', 'Condition.2', 'Bldg.Type',
       'House.Style', 'Overall.Qual', 'Overall.Cond', 'Year.Built',
       'Year.Remod.Add', 'Roof.Style', 'Roof.Matl', 'Exterior.1st',
       'Exterior.2nd', 'Mas.Vnr.Type', 'Mas.Vnr.Area', 'Exter.Qual',
       'Exter.Cond', 'Foundation', 'Bsmt.Qual', 'Bsmt.Cond', 'Bsmt.Exposure',
       'BsmtFin.Type.1', 'BsmtFin.SF.1', 'BsmtFin.Type.2', 'BsmtFin.SF.2',
       'Bsmt.Unf.SF', 'Total.Bsmt.SF', 'Heating', 'Heating.QC', 'Central.Air',
       'Electrical', 'X1st.Flr.SF', 'X2nd.Flr.SF', 'Low.Qual.Fin.SF',
       'Gr.Liv.Area', 'Bsmt.Full.Bath', 'Bsmt.Half.Bath', 'Full.Bath',
       'Half.Bath', 'Bedroom.AbvGr', 'Kitchen.AbvGr', 'Kitchen.Qual',
       'TotRms.AbvGrd', 'Functional', 'Fireplaces', 'Garage.Type',
       'Garage.Yr.Blt', 'Garage.Finish', 'Garage.Cars', 'Garage.Area',
       'Garage.Qual', 'Garage.Cond', 'Paved.Drive', 'Wood.Deck.SF',
       'Open.Porch.SF', 'Enclosed.Porch', 'X3Ssn.Porch', 'Screen.Porch',
       'Pool.Area', 'Misc.Val', 'Mo.Sold', 'Yr.Sold', 'Sale.Type',
       'Sale.Condition'],
      dtype='object')
</code></pre></div></div>

<p>Another option, especially with columns with missing values, is to impute the value but to include a column telling the model where the imputed values are.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ImputeWithDummy</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">cols_to_impute</span><span class="p">,</span> <span class="n">strategy</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="sh">'</span><span class="s">NA</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cols_to_impute</span> <span class="o">=</span> <span class="n">cols_to_impute</span>
        <span class="n">self</span><span class="p">.</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">strategy</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fill</span> <span class="o">=</span> <span class="n">fill</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">fill</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="sh">'</span><span class="s">median</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">fill</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">median</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mode</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">fill</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">mode</span><span class="p">().</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="sh">'</span><span class="s">fill</span><span class="sh">'</span><span class="p">:</span>
            <span class="k">if</span> <span class="nf">type</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">fill</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span> <span class="ow">and</span> <span class="nf">type</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="ow">is</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">fill</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">([(</span><span class="n">cname</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">cname</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">fill</span><span class="p">)])</span>
        <span class="k">return</span> <span class="n">self</span>
    
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">cols_to_impute</span><span class="p">:</span>
            <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">{}_missing</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">col</span><span class="p">)]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">fill</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">df</span>
    
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">ames.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="nc">ImputeWithDummy</span><span class="p">([</span><span class="sh">'</span><span class="s">Alley</span><span class="sh">'</span><span class="p">],</span> <span class="n">strategy</span><span class="o">=</span><span class="sh">'</span><span class="s">mode</span><span class="sh">'</span><span class="p">)</span>
<span class="n">X_transformed</span> <span class="o">=</span> <span class="n">imputer</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_transformed</span><span class="p">[[</span><span class="sh">'</span><span class="s">Alley</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Alley_missing</span><span class="sh">'</span><span class="p">]].</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Alley</th>
      <th>Alley_missing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Grvl</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Grvl</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Grvl</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Grvl</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Grvl</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<p>Of course, you should always read the data documentation (https://ww2.amstat.org/publications/jse/v19n3/decock/datadocumentation.txt), and there you’ll see for Alley that NaN means No Alley Access, and that we don’t need to any imputation at all!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NaNImpute</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">fill_vals</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cols</span> <span class="o">=</span> <span class="n">cols</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fill_vals</span> <span class="o">=</span> <span class="n">fill_vals</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span>
    
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">cols</span><span class="p">):</span>
            <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">fill_vals</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</code></pre></div></div>

<p>The other thing we’ll need to consider is that some columns will need to be converted to numeric features first, before an estimator can be fitted. First we’ll fit an imputer, and then encode.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DummyEncoding</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

        <span class="n">self</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">columns</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span>
    
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">get_dummies</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">impute_cols</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Alley</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Pool.QC</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Fence</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Misc.Feature</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Fireplace.Qu</span><span class="sh">'</span><span class="p">]</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([(</span><span class="sh">'</span><span class="s">impute</span><span class="sh">'</span><span class="p">,</span> <span class="nc">ImputeWithDummy</span><span class="p">(</span><span class="n">impute_cols</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="sh">'</span><span class="s">mode</span><span class="sh">'</span><span class="p">)),</span> <span class="p">(</span><span class="sh">'</span><span class="s">encode</span><span class="sh">'</span><span class="p">,</span> <span class="nc">DummyEncoding</span><span class="p">(</span><span class="n">impute_cols</span><span class="p">))])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">ames.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">X_trans</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_trans</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['Order', 'PID', 'MS.SubClass', 'MS.Zoning', 'Lot.Frontage', 'Lot.Area',
       'Street', 'Lot.Shape', 'Land.Contour', 'Utilities', 'Lot.Config',
       'Land.Slope', 'Neighborhood', 'Condition.1', 'Condition.2', 'Bldg.Type',
       'House.Style', 'Overall.Qual', 'Overall.Cond', 'Year.Built',
       'Year.Remod.Add', 'Roof.Style', 'Roof.Matl', 'Exterior.1st',
       'Exterior.2nd', 'Mas.Vnr.Type', 'Mas.Vnr.Area', 'Exter.Qual',
       'Exter.Cond', 'Foundation', 'Bsmt.Qual', 'Bsmt.Cond', 'Bsmt.Exposure',
       'BsmtFin.Type.1', 'BsmtFin.SF.1', 'BsmtFin.Type.2', 'BsmtFin.SF.2',
       'Bsmt.Unf.SF', 'Total.Bsmt.SF', 'Heating', 'Heating.QC', 'Central.Air',
       'Electrical', 'X1st.Flr.SF', 'X2nd.Flr.SF', 'Low.Qual.Fin.SF',
       'Gr.Liv.Area', 'Bsmt.Full.Bath', 'Bsmt.Half.Bath', 'Full.Bath',
       'Half.Bath', 'Bedroom.AbvGr', 'Kitchen.AbvGr', 'Kitchen.Qual',
       'TotRms.AbvGrd', 'Functional', 'Fireplaces', 'Garage.Type',
       'Garage.Yr.Blt', 'Garage.Finish', 'Garage.Cars', 'Garage.Area',
       'Garage.Qual', 'Garage.Cond', 'Paved.Drive', 'Wood.Deck.SF',
       'Open.Porch.SF', 'Enclosed.Porch', 'X3Ssn.Porch', 'Screen.Porch',
       'Pool.Area', 'Misc.Val', 'Mo.Sold', 'Yr.Sold', 'Sale.Type',
       'Sale.Condition', 'SalePrice', 'Alley_missing', 'Pool.QC_missing',
       'Fence_missing', 'Misc.Feature_missing', 'Fireplace.Qu_missing',
       'Alley_Pave', 'Pool.QC_Fa', 'Pool.QC_Gd', 'Pool.QC_TA', 'Fence_GdWo',
       'Fence_MnPrv', 'Fence_MnWw', 'Misc.Feature_Gar2', 'Misc.Feature_Othr',
       'Misc.Feature_Shed', 'Misc.Feature_TenC', 'Fireplace.Qu_Fa',
       'Fireplace.Qu_Gd', 'Fireplace.Qu_Po', 'Fireplace.Qu_TA'],
      dtype='object')
</code></pre></div></div>

<p>This dataset has several types of columns - continuous features encoded as ints and floats, but also some ordinal variables have snick in as ints. We’ll properly define all the int and float colukmns first:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">float_cols</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Lot.Frontage</span><span class="sh">'</span><span class="p">,</span> 
              <span class="sh">'</span><span class="s">Mas.Vnr.Area</span><span class="sh">'</span><span class="p">,</span> 
              <span class="sh">'</span><span class="s">BsmtFin.SF.1</span><span class="sh">'</span><span class="p">,</span> 
              <span class="sh">'</span><span class="s">BsmtFin.SF.2</span><span class="sh">'</span><span class="p">,</span> 
              <span class="sh">'</span><span class="s">Bsmt.Unf.SF</span><span class="sh">'</span><span class="p">,</span>
              <span class="sh">'</span><span class="s">Total.Bsmt.SF</span><span class="sh">'</span><span class="p">,</span>
              <span class="sh">'</span><span class="s">Garage.Cars</span><span class="sh">'</span><span class="p">,</span>
              <span class="sh">'</span><span class="s">Garage.Area</span><span class="sh">'</span>
             <span class="p">]</span>

<span class="n">int_cols</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">MS.SubClass</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Lot.Area</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">X1st.Flr.SF</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">X2nd.Flr.SF</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Low.Qual.Fin.SF</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Gr.Liv.Area</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Full.Bath</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Half.Bath</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Bedroom.AbvGr</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Kitchen.AbvGr</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">TotRms.AbvGrd</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Fireplaces</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Wood.Deck.SF</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Open.Porch.SF</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Enclosed.Porch</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">X3Ssn.Porch</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Screen.Porch</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Pool.Area</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Misc.Val</span><span class="sh">'</span>
           <span class="p">]</span>
</code></pre></div></div>

<p>Finally, we need some way to deal with ordinal features:</p>

<ul>
  <li>Lot Shape (Ordinal): General shape of property</li>
  <li>Utilities (Ordinal): Type of utilities available</li>
  <li>Land Slope (Ordinal): Slope of property</li>
  <li>Overall Qual (Ordinal): Rates the overall material and finish of the house</li>
  <li>Overall Cond (Ordinal): Rates the overall condition of the house</li>
  <li>Exter Qual (Ordinal): Evaluates the quality of the material on the exterior</li>
  <li>Exter Cond (Ordinal): Evaluates the present condition of the material on the exterior</li>
  <li>Bsmt Qual (Ordinal): Evaluates the height of the basement</li>
  <li>Bsmt Cond (Ordinal): Evaluates the general condition of the basement</li>
  <li>Bsmt Exposure	(Ordinal): Refers to walkout or garden level walls</li>
  <li>BsmtFin Type 1	(Ordinal): Rating of basement finished area</li>
  <li>BsmtFin Type 2	(Ordinal): Rating of basement finished area (if multiple types)</li>
  <li>HeatingQC (Ordinal): Heating quality and condition</li>
  <li>Electrical (Ordinal): Electrical system</li>
  <li>FireplaceQu (Ordinal): Fireplace quality</li>
  <li>Garage Finish (Ordinal)	: Interior finish of the garage</li>
  <li>Garage Qual (Ordinal): Garage quality</li>
  <li>Garage Cond (Ordinal): Garage condition</li>
  <li>Paved Drive (Ordinal): Paved driveway</li>
  <li>Pool QC (Ordinal): Pool quality</li>
  <li>Fence (Ordinal): Fence quality</li>
</ul>

<p>To do this we could use the OrdinalEncoder from http://contrib.scikit-learn.org/categorical-encoding/, which will be included in sklearn in a future release  - but I have trouble getting this to work with Pandas. Another choice is just to write our own. What we’ll do instead is to mix ordinal and categorical variables, and use the OneHotEncoder from the category_encoders package.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ord_cols</span>     <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Lot.Shape</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Utilities</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Land.Slope</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Overall.Qual</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Overall.Cond</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Exter.Qual</span><span class="sh">'</span><span class="p">,</span> 
                <span class="sh">'</span><span class="s">Exter.Cond</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Bsmt.Qual</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Bsmt.Cond</span><span class="sh">'</span><span class="p">,</span> 
                <span class="sh">'</span><span class="s">Bsmt.Exposure</span><span class="sh">'</span><span class="p">,</span> 
                <span class="sh">'</span><span class="s">BsmtFin.Type.1</span><span class="sh">'</span><span class="p">,</span> 
                <span class="sh">'</span><span class="s">BsmtFin.SF.1</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Heating.QC</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Electrical</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Fireplace.Qu</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Garage.Finish</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Garage.Qual</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Garage.Cond</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Paved.Drive</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Pool.QC</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Fence</span><span class="sh">'</span><span class="p">,</span>
               <span class="p">]</span>

<span class="n">cat_cols</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">MS.SubClass</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">MS.Zoning</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Street</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Alley</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Land.Contour</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Lot.Config</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Neighborhood</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Condition.1</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Condition.2</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Bldg.Type</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">House.Style</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Roof.Style</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Exterior.1st</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">Exterior.2nd</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Mas.Vnr.Type</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Foundation</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Heating</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Central.Air</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Garage.Type</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Misc.Feature</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Sale.Type</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Sale.Condition</span><span class="sh">'</span>
<span class="p">]</span>
</code></pre></div></div>

<p>Finally, we define a few useful transforms and put together our first pipeline.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DataFrameSelector</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">
    Select columns from pandas dataframe by specifying a list of column names
    </span><span class="sh">'''</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">col_names</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">col_names</span> <span class="o">=</span> <span class="n">col_names</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">col_names</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Scale</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">cols</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cols</span> <span class="o">=</span> <span class="n">cols</span>
        <span class="n">self</span><span class="p">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cols</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">columns</span>
        <span class="n">self</span><span class="p">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">index</span>
        <span class="k">return</span> <span class="n">self</span>
        
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">cols</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.externals.joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">FeatureUnion</span><span class="p">,</span> <span class="n">_fit_transform_one</span><span class="p">,</span> <span class="n">_transform_one</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>


<span class="k">class</span> <span class="nc">FeatureUnion</span><span class="p">(</span><span class="n">FeatureUnion</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_validate_transformers</span><span class="p">()</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nc">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">n_jobs</span><span class="p">)(</span>
            <span class="nf">delayed</span><span class="p">(</span><span class="n">_fit_transform_one</span><span class="p">)(</span><span class="n">trans</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                                        <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">trans</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="nf">_iter</span><span class="p">())</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">result</span><span class="p">:</span>
            <span class="c1"># All transformers are None
</span>            <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">Xs</span><span class="p">,</span> <span class="n">transformers</span> <span class="o">=</span> <span class="nf">zip</span><span class="p">(</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_update_transformer_list</span><span class="p">(</span><span class="n">transformers</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">any</span><span class="p">(</span><span class="n">sparse</span><span class="p">.</span><span class="nf">issparse</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">Xs</span><span class="p">):</span>
            <span class="n">Xs</span> <span class="o">=</span> <span class="n">sparse</span><span class="p">.</span><span class="nf">hstack</span><span class="p">(</span><span class="n">Xs</span><span class="p">).</span><span class="nf">tocsr</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Xs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">merge_dataframes_by_column</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Xs</span>

    <span class="k">def</span> <span class="nf">merge_dataframes_by_column</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="sh">"</span><span class="s">columns</span><span class="sh">"</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">Xs</span> <span class="o">=</span> <span class="nc">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">n_jobs</span><span class="p">)(</span>
            <span class="nf">delayed</span><span class="p">(</span><span class="n">_transform_one</span><span class="p">)(</span><span class="n">trans</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">trans</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="nf">_iter</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">Xs</span><span class="p">:</span>
            <span class="c1"># All transformers are None
</span>            <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
        <span class="k">if</span> <span class="nf">any</span><span class="p">(</span><span class="n">sparse</span><span class="p">.</span><span class="nf">issparse</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">Xs</span><span class="p">):</span>
            <span class="n">Xs</span> <span class="o">=</span> <span class="n">sparse</span><span class="p">.</span><span class="nf">hstack</span><span class="p">(</span><span class="n">Xs</span><span class="p">).</span><span class="nf">tocsr</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Xs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">merge_dataframes_by_column</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Xs</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">LabelBinarizer</span>
<span class="kn">from</span> <span class="n">category_encoders</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">numerical_cols</span> <span class="o">=</span> <span class="n">int_cols</span> <span class="o">+</span> <span class="n">float_cols</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">features</span><span class="sh">'</span><span class="p">,</span> <span class="nc">FeatureUnion</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">transformer_list</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">numericals</span><span class="sh">'</span><span class="p">,</span> <span class="nc">Pipeline</span><span class="p">([</span>
             <span class="p">(</span><span class="sh">'</span><span class="s">selector</span><span class="sh">'</span><span class="p">,</span> <span class="nc">DataFrameSelector</span><span class="p">(</span><span class="n">numerical_cols</span><span class="p">)),</span>
             <span class="p">(</span><span class="sh">'</span><span class="s">imputer</span><span class="sh">'</span><span class="p">,</span> <span class="nc">ImputeWithDummy</span><span class="p">(</span><span class="n">numerical_cols</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)),</span>
             <span class="c1">#('scaling', Scale(numerical_cols))
</span>        <span class="p">])),</span>
        
        <span class="c1">#('categoricals', Pipeline([
</span>        <span class="c1">#     ('selector', DataFrameSelector(cat_cols)), 
</span>        <span class="c1">#     ('encode', OneHotEncoder(cat_cols, return_df=True)),
</span>        <span class="c1">#])),
</span>        
        <span class="c1">#('NanImpute', Pipeline([
</span>        <span class="c1">##     ('selector', DataFrameSelector(['Alley', 'Pool.QC', 'Fence', 'Misc.Feature', 'Fireplace.Qu'])),
</span>        <span class="c1">#     ('nan_impute', NaNImpute(['Alley', 'Pool.QC', 'Fence', 'Misc.Feature', 'Fireplace.Qu'], 'Not Applicable'))
</span>        <span class="c1">#])),
</span>    <span class="p">])),</span> 
<span class="p">])</span>  
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">ames.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">PID</span><span class="sh">'</span><span class="p">).</span><span class="nf">copy</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_trans</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_trans</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MS.SubClass</th>
      <th>Lot.Area</th>
      <th>X1st.Flr.SF</th>
      <th>X2nd.Flr.SF</th>
      <th>Low.Qual.Fin.SF</th>
      <th>Gr.Liv.Area</th>
      <th>Full.Bath</th>
      <th>Half.Bath</th>
      <th>Bedroom.AbvGr</th>
      <th>Kitchen.AbvGr</th>
      <th>...</th>
      <th>Pool.Area_missing</th>
      <th>Misc.Val_missing</th>
      <th>Lot.Frontage_missing</th>
      <th>Mas.Vnr.Area_missing</th>
      <th>BsmtFin.SF.1_missing</th>
      <th>BsmtFin.SF.2_missing</th>
      <th>Bsmt.Unf.SF_missing</th>
      <th>Total.Bsmt.SF_missing</th>
      <th>Garage.Cars_missing</th>
      <th>Garage.Area_missing</th>
    </tr>
    <tr>
      <th>PID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>526301100</th>
      <td>20</td>
      <td>31770</td>
      <td>1656</td>
      <td>0</td>
      <td>0</td>
      <td>1656</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>526350040</th>
      <td>20</td>
      <td>11622</td>
      <td>896</td>
      <td>0</td>
      <td>0</td>
      <td>896</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>526351010</th>
      <td>20</td>
      <td>14267</td>
      <td>1329</td>
      <td>0</td>
      <td>0</td>
      <td>1329</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>526353030</th>
      <td>20</td>
      <td>11160</td>
      <td>2110</td>
      <td>0</td>
      <td>0</td>
      <td>2110</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527105010</th>
      <td>60</td>
      <td>13830</td>
      <td>928</td>
      <td>701</td>
      <td>0</td>
      <td>1629</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527105030</th>
      <td>60</td>
      <td>9978</td>
      <td>926</td>
      <td>678</td>
      <td>0</td>
      <td>1604</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527127150</th>
      <td>120</td>
      <td>4920</td>
      <td>1338</td>
      <td>0</td>
      <td>0</td>
      <td>1338</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527145080</th>
      <td>120</td>
      <td>5005</td>
      <td>1280</td>
      <td>0</td>
      <td>0</td>
      <td>1280</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527146030</th>
      <td>120</td>
      <td>5389</td>
      <td>1616</td>
      <td>0</td>
      <td>0</td>
      <td>1616</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527162130</th>
      <td>60</td>
      <td>7500</td>
      <td>1028</td>
      <td>776</td>
      <td>0</td>
      <td>1804</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527163010</th>
      <td>60</td>
      <td>10000</td>
      <td>763</td>
      <td>892</td>
      <td>0</td>
      <td>1655</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527165230</th>
      <td>20</td>
      <td>7980</td>
      <td>1187</td>
      <td>0</td>
      <td>0</td>
      <td>1187</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527166040</th>
      <td>60</td>
      <td>8402</td>
      <td>789</td>
      <td>676</td>
      <td>0</td>
      <td>1465</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527180040</th>
      <td>20</td>
      <td>10176</td>
      <td>1341</td>
      <td>0</td>
      <td>0</td>
      <td>1341</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527182190</th>
      <td>120</td>
      <td>6820</td>
      <td>1502</td>
      <td>0</td>
      <td>0</td>
      <td>1502</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527216070</th>
      <td>60</td>
      <td>53504</td>
      <td>1690</td>
      <td>1589</td>
      <td>0</td>
      <td>3279</td>
      <td>3</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527225035</th>
      <td>50</td>
      <td>12134</td>
      <td>1080</td>
      <td>672</td>
      <td>0</td>
      <td>1752</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527258010</th>
      <td>20</td>
      <td>11394</td>
      <td>1856</td>
      <td>0</td>
      <td>0</td>
      <td>1856</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527276150</th>
      <td>20</td>
      <td>19138</td>
      <td>864</td>
      <td>0</td>
      <td>0</td>
      <td>864</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527302110</th>
      <td>20</td>
      <td>13175</td>
      <td>2073</td>
      <td>0</td>
      <td>0</td>
      <td>2073</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527358140</th>
      <td>20</td>
      <td>11751</td>
      <td>1844</td>
      <td>0</td>
      <td>0</td>
      <td>1844</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527358200</th>
      <td>85</td>
      <td>10625</td>
      <td>1173</td>
      <td>0</td>
      <td>0</td>
      <td>1173</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527368020</th>
      <td>60</td>
      <td>7500</td>
      <td>814</td>
      <td>860</td>
      <td>0</td>
      <td>1674</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527402200</th>
      <td>20</td>
      <td>11241</td>
      <td>1004</td>
      <td>0</td>
      <td>0</td>
      <td>1004</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527402250</th>
      <td>20</td>
      <td>12537</td>
      <td>1078</td>
      <td>0</td>
      <td>0</td>
      <td>1078</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527403020</th>
      <td>20</td>
      <td>8450</td>
      <td>1056</td>
      <td>0</td>
      <td>0</td>
      <td>1056</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527404120</th>
      <td>20</td>
      <td>8400</td>
      <td>882</td>
      <td>0</td>
      <td>0</td>
      <td>882</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527425090</th>
      <td>20</td>
      <td>10500</td>
      <td>864</td>
      <td>0</td>
      <td>0</td>
      <td>864</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527427230</th>
      <td>120</td>
      <td>5858</td>
      <td>1337</td>
      <td>0</td>
      <td>0</td>
      <td>1337</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>527451180</th>
      <td>160</td>
      <td>1680</td>
      <td>483</td>
      <td>504</td>
      <td>0</td>
      <td>987</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>916477010</th>
      <td>20</td>
      <td>13618</td>
      <td>1960</td>
      <td>0</td>
      <td>0</td>
      <td>1960</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>921205030</th>
      <td>20</td>
      <td>11443</td>
      <td>2028</td>
      <td>0</td>
      <td>0</td>
      <td>2028</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>921205050</th>
      <td>20</td>
      <td>11577</td>
      <td>1838</td>
      <td>0</td>
      <td>0</td>
      <td>1838</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923125030</th>
      <td>20</td>
      <td>31250</td>
      <td>1600</td>
      <td>0</td>
      <td>0</td>
      <td>1600</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923202025</th>
      <td>90</td>
      <td>7020</td>
      <td>1368</td>
      <td>0</td>
      <td>0</td>
      <td>1368</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923203090</th>
      <td>120</td>
      <td>4500</td>
      <td>1216</td>
      <td>0</td>
      <td>0</td>
      <td>1216</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923203100</th>
      <td>120</td>
      <td>4500</td>
      <td>1337</td>
      <td>0</td>
      <td>0</td>
      <td>1337</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923205120</th>
      <td>20</td>
      <td>17217</td>
      <td>1140</td>
      <td>0</td>
      <td>0</td>
      <td>1140</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923225190</th>
      <td>160</td>
      <td>2665</td>
      <td>616</td>
      <td>688</td>
      <td>0</td>
      <td>1304</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923225240</th>
      <td>160</td>
      <td>2665</td>
      <td>925</td>
      <td>550</td>
      <td>0</td>
      <td>1475</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923225260</th>
      <td>160</td>
      <td>3964</td>
      <td>1291</td>
      <td>1230</td>
      <td>0</td>
      <td>2521</td>
      <td>2</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923225510</th>
      <td>20</td>
      <td>10172</td>
      <td>874</td>
      <td>0</td>
      <td>0</td>
      <td>874</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923226150</th>
      <td>90</td>
      <td>11836</td>
      <td>1652</td>
      <td>0</td>
      <td>0</td>
      <td>1652</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923226180</th>
      <td>180</td>
      <td>1470</td>
      <td>630</td>
      <td>0</td>
      <td>0</td>
      <td>630</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923226290</th>
      <td>160</td>
      <td>1484</td>
      <td>546</td>
      <td>546</td>
      <td>0</td>
      <td>1092</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923227100</th>
      <td>20</td>
      <td>13384</td>
      <td>1360</td>
      <td>0</td>
      <td>0</td>
      <td>1360</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923228130</th>
      <td>180</td>
      <td>1533</td>
      <td>630</td>
      <td>0</td>
      <td>0</td>
      <td>630</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923228180</th>
      <td>160</td>
      <td>1533</td>
      <td>546</td>
      <td>546</td>
      <td>0</td>
      <td>1092</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923228210</th>
      <td>160</td>
      <td>1526</td>
      <td>546</td>
      <td>546</td>
      <td>0</td>
      <td>1092</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923228260</th>
      <td>160</td>
      <td>1936</td>
      <td>546</td>
      <td>546</td>
      <td>0</td>
      <td>1092</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923228310</th>
      <td>160</td>
      <td>1894</td>
      <td>546</td>
      <td>546</td>
      <td>0</td>
      <td>1092</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923229110</th>
      <td>90</td>
      <td>12640</td>
      <td>1728</td>
      <td>0</td>
      <td>0</td>
      <td>1728</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923230040</th>
      <td>90</td>
      <td>9297</td>
      <td>1728</td>
      <td>0</td>
      <td>0</td>
      <td>1728</td>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>2</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923250060</th>
      <td>20</td>
      <td>17400</td>
      <td>1126</td>
      <td>0</td>
      <td>0</td>
      <td>1126</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923251180</th>
      <td>20</td>
      <td>20000</td>
      <td>1224</td>
      <td>0</td>
      <td>0</td>
      <td>1224</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923275080</th>
      <td>80</td>
      <td>7937</td>
      <td>1003</td>
      <td>0</td>
      <td>0</td>
      <td>1003</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923276100</th>
      <td>20</td>
      <td>8885</td>
      <td>902</td>
      <td>0</td>
      <td>0</td>
      <td>902</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>923400125</th>
      <td>85</td>
      <td>10441</td>
      <td>970</td>
      <td>0</td>
      <td>0</td>
      <td>970</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>924100070</th>
      <td>20</td>
      <td>10010</td>
      <td>1389</td>
      <td>0</td>
      <td>0</td>
      <td>1389</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>924151050</th>
      <td>60</td>
      <td>9627</td>
      <td>996</td>
      <td>1004</td>
      <td>0</td>
      <td>2000</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>2930 rows × 54 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">l</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">X_trans</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">"</span><span class="s">ignore</span><span class="sh">"</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([(</span><span class="sh">'</span><span class="s">pipeline</span><span class="sh">'</span><span class="p">,</span> <span class="n">pipe</span><span class="p">),</span> <span class="p">(</span><span class="sh">'</span><span class="s">clf</span><span class="sh">'</span><span class="p">,</span> <span class="nc">LarsCV</span><span class="p">())])</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Pipeline(memory=None,
     steps=[('pipeline', Pipeline(memory=None,
     steps=[('features', FeatureUnion(n_jobs=1,
       transformer_list=[('numericals', Pipeline(memory=None,
     steps=[('selector', DataFrameSelector(col_names=['MS.SubClass', 'Lot.Area', 'X1st.Flr.SF', 'X2nd.Flr.SF', 'Low.Qual.Fin.SF', 'Gr.Liv.Area', 'Fu...max_n_alphas=1000, n_jobs=1, normalize=True,
    positive=False, precompute='auto', verbose=False))])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipe</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">).</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['MS.SubClass', 'Lot.Area', 'X1st.Flr.SF', 'X2nd.Flr.SF',
       'Low.Qual.Fin.SF', 'Gr.Liv.Area', 'Full.Bath', 'Half.Bath',
       'Bedroom.AbvGr', 'Kitchen.AbvGr', 'TotRms.AbvGrd', 'Fireplaces',
       'Wood.Deck.SF', 'Open.Porch.SF', 'Enclosed.Porch', 'X3Ssn.Porch',
       'Screen.Porch', 'Pool.Area', 'Misc.Val', 'Lot.Frontage', 'Mas.Vnr.Area',
       'BsmtFin.SF.1', 'BsmtFin.SF.2', 'Bsmt.Unf.SF', 'Total.Bsmt.SF',
       'Garage.Cars', 'Garage.Area', 'MS.SubClass_missing', 'Lot.Area_missing',
       'X1st.Flr.SF_missing', 'X2nd.Flr.SF_missing', 'Low.Qual.Fin.SF_missing',
       'Gr.Liv.Area_missing', 'Full.Bath_missing', 'Half.Bath_missing',
       'Bedroom.AbvGr_missing', 'Kitchen.AbvGr_missing',
       'TotRms.AbvGrd_missing', 'Fireplaces_missing', 'Wood.Deck.SF_missing',
       'Open.Porch.SF_missing', 'Enclosed.Porch_missing',
       'X3Ssn.Porch_missing', 'Screen.Porch_missing', 'Pool.Area_missing',
       'Misc.Val_missing', 'Lot.Frontage_missing', 'Mas.Vnr.Area_missing',
       'BsmtFin.SF.1_missing', 'BsmtFin.SF.2_missing', 'Bsmt.Unf.SF_missing',
       'Total.Bsmt.SF_missing', 'Garage.Cars_missing', 'Garage.Area_missing'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="k">def</span> <span class="nf">rmse_cv</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">rmse</span><span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="o">-</span><span class="nf">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">"</span><span class="s">neg_mean_squared_error</span><span class="sh">"</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    <span class="nf">return</span><span class="p">(</span><span class="n">rmse</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">rmse_cv</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([37647.53964453, 71123.27879506])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="k">def</span> <span class="nf">get_score</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>    
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">R2: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">r2_score</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">labels</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">get_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R2: 0.6208433062823728
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/03/05/More-Complex-Regularised-Linear-Regressions.html"><h2 class="larger">More Complex Regularised Linear Regressions</h2></a>
          <br><span class="smaller">March 5, 2021</span>  <br/>
          <div><p>We have previously considered models of the form:</p>

\[\hat{y} = \beta X + w\]

<p>where we have measured how well the model is doing by minimising the function:</p>

\[J\left( \beta \right) = \frac{1}{n} \lVert y - \hat{y} \rVert\]

<p>However, this method doesn’t allow us to encode some of the ideas we may have about \(\beta\).</p>

<p>In least squares regression we are (essentially) solving a series of equations:</p>

\[y = X \beta\]

<p>but the problem may be ill posed: there may be no \(\beta\), or many, which satisfy the above equation. Also, many systems we are interested in moddeling act like low-pass filters going in the direction \(X \beta\), so inverting the system naively will act like a high-pass filter and will amplify noise. We can give preference to particular solutions by instead minimising:</p>

\[J\left( \theta \right) = \frac{1}{n} \lVert y - \hat{y} \rVert_2^2 + \lVert \Gamma \beta \rVert_2^2\]

<p>Luckily, this equation has a closed form solution:</p>

\[\hat{\beta} = \left(X^T X + \Gamma^T \Gamma \right)^{-1} X^T y\]

<p>which can be found the same way as the closed form solution for Linear Regression. A particularly important case is \(\Gamma = \lambda 1\) (a constant times the identity matrix), which is known by the name of Ridge Regression.</p>

<p>Sometimes we have more complex priors about which solutions we require from any particular optimisation problem, and many cannot be solved by simply taking the gradient. For example</p>

\[J\left( \theta \right) = \frac{1}{n} \lVert y - \hat{y} \rVert_2^2 + \lVert \beta \rVert_1\]

<p>this optimisation problem is non differentiable! Or consider</p>

\[J\left( \theta \right) = \frac{1}{n} \lVert y - \hat{y} \rVert_2^2 + \lVert \nabla \beta \rVert_1\]

<p>or</p>

\[J\left( \theta \right) = \frac{1}{n} \lVert y - \hat{y} \rVert_2^2 + \lVert \beta \rVert_0\]

<p>where</p>

\[\lVert \beta \rVert_0 = \{\beta \neq 0 \}\]

<p>None of these optimisation problems can be solved in the straightforward way that we solved Ridge regression.</p>

<p>These optimisation problem can be solved by using the following trick, set</p>

\[z = \beta\]

<p>in the second term, and then optimise the following function (the last term is to enforce the constraint we introduced):</p>

\[J\left( \beta \right) = \frac{1}{n} \lVert y - \beta^T X\rVert_2^2 + \lambda \lVert z \rVert_2^2 + \nu^T \left(\beta - z\right) + \frac{\rho}{2} \lVert\beta -z\rVert_2^2\]

<p>This is cleverer than it looks, because</p>

\[\frac{\partial J}{\partial \beta} = -X^T \left(y - X\beta\right) + \rho\left(\beta - z\right) + \nu^T\]

<p>and</p>

\[\frac{\partial J}{\partial z} = \lambda - \nu^T - \rho\left( \beta - z\right)\]

<p>for \( z &gt; 0 \), and</p>

\[\frac{\partial J}{\partial z} = - \lambda - \nu^T + \rho\left( \beta - z\right)\]

<p>for \( z &lt; 0 \), and</p>

\[-\frac{\lambda}{\rho} \leq x + \frac{\nu}{\rho} \leq \frac{\lambda}{\rho}\]

<p>combining these we find:</p>

\[z = \mathrm{sign}\left(X + \frac{\nu}{\rho}\right) \mathrm{max} \left(\mid X + \frac{\nu}{\rho} \mid - \frac{\lambda}{\rho}, 0 \right)\]

<p>we can then update our weights by the following set of iterates:</p>

\[X^{k+1} = \left(X^T X + \rho I\right)^{-1} \left(X^t y + \rho \left(z^{k} - \nu^{k}\right)\right)\]

\[z^{k+1} = S_{\frac{\lambda}{\rho}}\left(X^{k+1} + \nu^{k}/\rho\right)\]

\[\nu^{k+1} = n^{k} + \rho \left(x^{k+1} - z^{k+1} \right)\]

<p>This is implemented in the code below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="k">def</span> <span class="nf">l2prox</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
    <span class="nf">return </span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">mu</span><span class="p">))</span> <span class="o">*</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">l1prox</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sign</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">absolute</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">-</span><span class="n">mu</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">ADMM</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rho</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">prox</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Alternating Direction Method of Multipliers

    This is a python implementation of the Alternating Direction
    Method of Multipliers - a method of constrained optimisation
    that is used widely in statistics (http://stanford.edu/~boyd/admm.html).
    </span><span class="sh">"""</span>

    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">A</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">A_t_A</span> <span class="o">=</span> <span class="n">A</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">w</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">eig</span><span class="p">(</span><span class="n">A_t_A</span><span class="p">)</span>
    <span class="n">MAX_ITER</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1">#Function to caluculate min 1/2(y - Ax) + l||x||
</span>    <span class="c1">#via alternating direction methods
</span>    <span class="n">x_hat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">z_hat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="c1">#Calculate regression co-efficient and stepsize
</span>    <span class="c1"># r = np.amax(np.absolute(w))
</span>    <span class="c1"># l_over_rho = np.sqrt(2*np.log(n)) * r / 2.0 # I might be wrong here
</span>    <span class="c1"># rho = mu/r
</span>
    <span class="c1">#Pre-compute to save some multiplications
</span>    <span class="n">A_t_y</span> <span class="o">=</span> <span class="n">A</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="n">A_t_A</span> <span class="o">+</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">identity</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">inv</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
    <span class="n">Q_dot</span> <span class="o">=</span> <span class="n">Q</span><span class="p">.</span><span class="n">dot</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">MAX_ITER</span><span class="p">):</span>
        <span class="c1">#x minimisation step via posterier OLS
</span>        <span class="n">x_hat</span> <span class="o">=</span> <span class="nc">Q_dot</span><span class="p">(</span><span class="n">A_t_y</span> <span class="o">+</span> <span class="n">rho</span><span class="o">*</span><span class="p">(</span><span class="n">z_hat</span> <span class="o">-</span> <span class="n">u</span><span class="p">))</span>
        <span class="n">z_hat</span> <span class="o">=</span> <span class="nf">prox</span><span class="p">(</span><span class="n">x_hat</span> <span class="o">+</span> <span class="n">u</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
        <span class="c1">#mulitplier update
</span>        <span class="n">u</span> <span class="o">=</span> <span class="n">u</span>  <span class="o">+</span> <span class="n">rho</span><span class="o">*</span><span class="p">(</span><span class="n">x_hat</span> <span class="o">-</span> <span class="n">z_hat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z_hat</span>

<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">computed</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Plot two vectors to compare their values</span><span class="sh">"""</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Original</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">computed</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Estimate</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">original</span> <span class="o">-</span> <span class="n">computed</span><span class="p">)</span>
    

    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">'</span><span class="s">upper right</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Test the ADMM method with randomly generated matrices and vectors</span><span class="sh">"""</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="n">num_non_zeros</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">positions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">num_non_zeros</span><span class="p">)</span>
    <span class="n">amplitudes</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">num_non_zeros</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">x</span><span class="p">[</span><span class="n">positions</span><span class="p">]</span> <span class="o">=</span> <span class="n">amplitudes</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">A</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1">#+ np.random.randn(m, 1)
</span>
    <span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nc">ADMM</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">l1prox</span><span class="p">))</span>

<span class="nf">test</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No handles with labels found to put in legend.
</code></pre></div></div>

<p><img src="2021-03-05-More-Complex-Regularised-Linear-Regressions_files/2021-03-05-More-Complex-Regularised-Linear-Regressions_1_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/03/02/Local-Linear-trend-models-for-time-series.html"><h2 class="larger">Local Linear Trend Models For Time Series</h2></a>
          <br><span class="smaller">March 2, 2021</span>  <br/>
          <div><p>Local Linear Trend models are one of the simplest time series models, and can be expressed by the following equations:</p>

\[v_t \sim N\left(v_t, \sigma_v^2\right)\]

\[x_t \sim N\left(x_{t-1} + v_{t-1}, \sigma_x^2\right)\]

\[y_t \sim N\left(x_t, \sigma_y^2\right)\]

<p>Where $\sigma_x^2$ is the observation error, $\sigma_y^2$ is the level disturbance, and $\sigma_v^2$ is the slope distrubance</p>

<p>We will model this in pystan, using the air passengers dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pystan</span>
<span class="kn">import</span> <span class="n">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">'</span><span class="s">ggplot</span><span class="sh">'</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">passengers</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">passengers.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="sh">'</span><span class="s">;</span><span class="sh">'</span><span class="p">)</span>
<span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Month</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Month</span><span class="sh">'</span><span class="p">])</span>
<span class="n">passengers</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">Month</span><span class="sh">'</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">passengers</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1eb1f828&gt;
</code></pre></div></div>

<p><img src="2021-03-02-Local-Linear-trend-models-for-time-series_files/2021-03-02-Local-Linear-trend-models-for-time-series_1_1.png" alt="png" /></p>

<p>In stan we can write out model as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stan_code</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">data {
    int N;
    vector[N] X;
}

parameters {
    vector[N] u;
    vector[N] v;
    real&lt;lower=0&gt; s_u;
    real&lt;lower=0&gt; s_v;
    real&lt;lower=0&gt; s_x;
}

model {
    v[2:N] ~ normal(v[1:N-1], s_v);
    u[2:N] ~ normal(u[1:N-1] + v[1:N-1], s_u);
    X ~ normal(u, s_x);
}</span><span class="sh">"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_feed</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">X</span><span class="sh">'</span><span class="p">:</span> <span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="sh">'</span><span class="s">N</span><span class="sh">'</span><span class="p">:</span> <span class="n">passengers</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]}</span>
<span class="n">sm</span> <span class="o">=</span> <span class="n">pystan</span><span class="p">.</span><span class="nc">StanModel</span><span class="p">(</span><span class="n">model_code</span><span class="o">=</span><span class="n">stan_code</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">sampling</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_feed</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_ae1b8f06975ee0f66c2a6bd10f156f5b NOW.
</code></pre></div></div>

<p>We can visually check the fit and the parameters with:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">mpl</span><span class="p">.</span><span class="nf">rc_context</span><span class="p">():</span>
    <span class="n">mpl</span><span class="p">.</span><span class="nf">rc</span><span class="p">(</span><span class="sh">'</span><span class="s">figure</span><span class="sh">'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">fit</span><span class="p">.</span><span class="nf">plot</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="2021-03-02-Local-Linear-trend-models-for-time-series_files/2021-03-02-Local-Linear-trend-models-for-time-series_6_0.png" alt="png" /></p>

<p>And we can also check the in sample fit visually:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span> <span class="o">=</span> <span class="n">fit</span><span class="p">.</span><span class="nf">extract</span><span class="p">(</span><span class="n">permuted</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">u_mean</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="sh">'</span><span class="s">u</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">u_mean</span>
<span class="n">passengers</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1ff665c0&gt;
</code></pre></div></div>

<p><img src="2021-03-02-Local-Linear-trend-models-for-time-series_files/2021-03-02-Local-Linear-trend-models-for-time-series_9_1.png" alt="png" /></p>

<p>To predict future points, we have to include the extra points in the original stan code</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stan_code</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">data {
    int N;
    vector[N] X;
    int pred_num; 
}

parameters {
    vector[N] u;
    vector[N] v;
    real&lt;lower=0&gt; s_u;
    real&lt;lower=0&gt; s_v;
    real&lt;lower=0&gt; s_x;
}

model {
    v[2:N] ~ normal(v[1:N-1], s_v);
    u[2:N] ~ normal(u[1:N-1] + v[1:N-1], s_u);
    X ~ normal(u, s_x);
}
    
generated quantities {
    vector[N + pred_num] u_pred;
    vector[pred_num] x_pred;
    u_pred[1:N] = u;
    for (i in 1:pred_num) {
        u_pred[N+i] = normal_rng(u_pred[N+i-1], s_u);
        x_pred[i] = normal_rng(u_pred[N+i], s_x);
    }
}
</span><span class="sh">"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_feed</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">X</span><span class="sh">'</span><span class="p">:</span> <span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="sh">'</span><span class="s">N</span><span class="sh">'</span><span class="p">:</span> <span class="n">passengers</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="sh">'</span><span class="s">pred_num</span><span class="sh">'</span><span class="p">:</span><span class="mi">10</span><span class="p">}</span>
<span class="n">sm</span> <span class="o">=</span> <span class="n">pystan</span><span class="p">.</span><span class="nc">StanModel</span><span class="p">(</span><span class="n">model_code</span><span class="o">=</span><span class="n">stan_code</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">sampling</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_feed</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_cc645429411ff4903a697d8562e07c6d NOW.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span> <span class="o">=</span> <span class="n">fit</span><span class="p">.</span><span class="nf">extract</span><span class="p">(</span><span class="n">permuted</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">u_mean</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="sh">'</span><span class="s">u</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">u_pred</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="sh">'</span><span class="s">u_pred</span><span class="sh">'</span><span class="p">][:]</span>
<span class="n">pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">u_pred</span><span class="p">).</span><span class="n">T</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">u_mean</span>
<span class="n">passengers</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a204ff0b8&gt;
</code></pre></div></div>

<p><img src="2021-03-02-Local-Linear-trend-models-for-time-series_files/2021-03-02-Local-Linear-trend-models-for-time-series_14_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">date_range</span><span class="p">(</span><span class="sh">'</span><span class="s">1961-01</span><span class="sh">'</span><span class="p">,</span> <span class="n">periods</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="sh">'</span><span class="s">MS</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">passengers</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">passengers</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="n">passengers</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">df_</span><span class="p">,</span> <span class="n">pred_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_</span><span class="p">[[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]].</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1f9f33c8&gt;
</code></pre></div></div>

<p><img src="2021-03-02-Local-Linear-trend-models-for-time-series_files/2021-03-02-Local-Linear-trend-models-for-time-series_19_1.png" alt="png" /></p>

<p>So, even though our model has a good in-sample fit, the out of sample predictions are very poor. To solve this, we can add a seasonal component:</p>

\[u_t \sim N\left(u_{t-1}, \sigma_v^2\right)\]

\[s_t \sim N\left(-\sum^n_{l=1}s_{t-l}, \sigma_s\right)\]

\[y_t \sim N\left(u_t + s_t, \sigma_y^2\right)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stan_code</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">data {
    int N;
    int pred_num;
    vector[N] y;
}

parameters {
    vector[N] s;
    vector[N] u;
    real&lt;lower=0&gt; s_s;
    real&lt;lower=0&gt; s_u;
    real&lt;lower=0&gt; s_y;
}

model {
    s[12:N] ~ normal(-s[1:N-11]-s[2:N-10]-s[3:N-9]-s[4:N-8]-s[5:N-7]-s[6:N-6]-s[7:N-5]-s[8:N-4]-s[9:N-3]-s[10:N-2]-s[11:N-1], s_s);
    u[2:N] ~ normal(u[1:N-1], s_u);
    y ~ normal(u+s, s_y);
}

generated quantities {
    vector[N+pred_num] s_pred;
    vector[N+pred_num] u_pred;
    vector[N+pred_num] y_pred;

    s_pred[1:N] = s;
    u_pred[1:N] = u;
    y_pred[1:N] = y;

    for (t in (N+1):(N+pred_num)){
        s_pred[t] = normal_rng(-s_pred[t-11]-s_pred[t-10]-s_pred[t-9]-s_pred[t-8]-s_pred[t-7]-s_pred[t-6]-s_pred[t-5]-s_pred[t-4]-s_pred[t-3]-s_pred[t-2]-s_pred[t-1], s_s);
        u_pred[t] = normal_rng(u_pred[t-1], s_u);
        y_pred[t] = normal_rng(u_pred[t]+s_pred[t], s_y);
    }
}
</span><span class="sh">"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_feed</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">:</span> <span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="sh">'</span><span class="s">N</span><span class="sh">'</span><span class="p">:</span> <span class="n">passengers</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="sh">'</span><span class="s">pred_num</span><span class="sh">'</span><span class="p">:</span><span class="mi">10</span><span class="p">}</span>
<span class="n">sm</span> <span class="o">=</span> <span class="n">pystan</span><span class="p">.</span><span class="nc">StanModel</span><span class="p">(</span><span class="n">model_code</span><span class="o">=</span><span class="n">stan_code</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">sampling</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_feed</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_65ffdf38c841c93de59a3d4d247dc640 NOW.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span> <span class="o">=</span> <span class="n">fit</span><span class="p">.</span><span class="nf">extract</span><span class="p">(</span><span class="n">permuted</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">u_mean</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="sh">'</span><span class="s">u</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">u_pred</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="sh">'</span><span class="s">y_pred</span><span class="sh">'</span><span class="p">][:]</span>
<span class="n">pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">u_pred</span><span class="p">).</span><span class="n">T</span>

<span class="n">df_</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">passengers</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">passengers</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">df_</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">passengers</span><span class="p">[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">]</span>
<span class="n">pred_df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="n">passengers</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">df_</span><span class="p">,</span> <span class="n">pred_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_</span><span class="p">[[</span><span class="sh">'</span><span class="s">Passengers</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">,</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]].</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a2118a278&gt;
</code></pre></div></div>

<p><img src="2021-03-02-Local-Linear-trend-models-for-time-series_files/2021-03-02-Local-Linear-trend-models-for-time-series_23_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s_pred</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="sh">'</span><span class="s">s_pred</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">s_pred</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span> <span class="n">s_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x1a25972710&gt;]
</code></pre></div></div>

<p><img src="2021-03-02-Local-Linear-trend-models-for-time-series_files/2021-03-02-Local-Linear-trend-models-for-time-series_24_1.png" alt="png" /></p>

<p>These out of sample predicitons look much better!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/03/01/bayesian-feature-selection.html"><h2 class="larger">Bayesian Feature Selection</h2></a>
          <br><span class="smaller">March 1, 2021</span>  <br/>
          <div><p>In this post we’ll discuss some ways of doing feature selection within a Bayesian framework</p>

<p>Let \(y\) be a set of real-valued observations. The basic linear regression model can be decribed as</p>

\[y_t = \beta^Tx + \varepsilon_t\]

<p>Where \( \varepsilon \sim N\left(0, \sigma^2\right) \). This can be equivalently written:</p>

<p>\(y \sim N\left(\beta^Tx, \sigma^2\right)\).</p>

<p>We will first place a prior on \(\beta\), like:</p>

\[\beta_i \sim \left(\frac{\tau}{2}\right)^p \mathrm{exp}\left(-\tau \mid\beta\mid \right)\]

<p>Then we will use the horseshoe prior:</p>

\[\beta_i \sim N\left(0, \lambda_i\right)\]

\[\lambda_i \sim \mathrm{Cauchy}^+\left(0, \tau\right)\]

\[\tau \sim \mathrm{Cauchy}^+\left(0, 1\right)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pymc3</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">import</span> <span class="n">theano</span>
<span class="kn">import</span> <span class="n">theano.tensor</span> <span class="k">as</span> <span class="n">T</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">'</span><span class="s">ggplot</span><span class="sh">'</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="kn">from</span> <span class="n">pymc3_models.exc</span> <span class="kn">import</span> <span class="n">PyMC3ModelsError</span>
<span class="kn">from</span> <span class="n">pymc3_models.models</span> <span class="kn">import</span> <span class="n">BayesianModel</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BayesianLassoRegression</span><span class="p">(</span><span class="n">BayesianModel</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Linear Regression built using PyMC3.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">BayesianLassoRegression</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ppc</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Creates and returns the PyMC3 model.
        Note: The size of the shared variables must match the size of the training data. Otherwise, setting the shared variables later will raise an error. See http://docs.pymc.io/advanced_theano.html
        Returns
        ----------
        the PyMC3 model
        </span><span class="sh">"""</span>
        <span class="n">model_input</span> <span class="o">=</span> <span class="n">theano</span><span class="p">.</span><span class="nf">shared</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_pred</span><span class="p">]))</span>

        <span class="n">model_output</span> <span class="o">=</span> <span class="n">theano</span><span class="p">.</span><span class="nf">shared</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span><span class="p">))</span>

        <span class="n">self</span><span class="p">.</span><span class="n">shared_vars</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">model_input</span><span class="sh">'</span><span class="p">:</span> <span class="n">model_input</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">model_output</span><span class="sh">'</span><span class="p">:</span> <span class="n">model_output</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Model</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">model</span><span class="p">:</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Laplace</span><span class="p">(</span><span class="sh">'</span><span class="s">beta</span><span class="sh">'</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_pred</span><span class="p">))</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">HalfNormal</span><span class="p">(</span><span class="sh">'</span><span class="s">sigma</span><span class="sh">'</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
            <span class="n">ll</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">model_input</span><span class="p">,</span> <span class="n">beta</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">ll</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">model_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">inference_type</span><span class="o">=</span><span class="sh">'</span><span class="s">nuts</span><span class="sh">'</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">inference_args</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">draws</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1000</span><span class="p">}):</span>
        <span class="sh">"""</span><span class="s">
        Train the Linear Regression model
        Parameters
        ----------
        X : numpy array, shape [n_samples, n_features]
        y : numpy array, shape [n_samples, ]
        inference_type : string, specifies which inference method to call. Defaults to </span><span class="sh">'</span><span class="s">advi</span><span class="sh">'</span><span class="s">. Currently, only </span><span class="sh">'</span><span class="s">advi</span><span class="sh">'</span><span class="s"> and </span><span class="sh">'</span><span class="s">nuts</span><span class="sh">'</span><span class="s"> are supported
        minibatch_size : number of samples to include in each minibatch for ADVI, defaults to None, so minibatch is not run by default
        inference_args : dict, arguments to be passed to the inference methods. Check the PyMC3 docs for permissable values. If no arguments are specified, default values will be set.
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_pred</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

        <span class="n">self</span><span class="p">.</span><span class="n">inference_type</span> <span class="o">=</span> <span class="n">inference_type</span>

        <span class="k">if</span> <span class="n">y</span><span class="p">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">inference_args</span><span class="p">:</span>
            <span class="n">inference_args</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_set_default_inference_args</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">create_model</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">minibatch_size</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span><span class="p">:</span>
                <span class="n">minibatches</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">shared_vars</span><span class="p">[</span><span class="sh">'</span><span class="s">model_input</span><span class="sh">'</span><span class="p">]:</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Minibatch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">),</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">shared_vars</span><span class="p">[</span><span class="sh">'</span><span class="s">model_output</span><span class="sh">'</span><span class="p">]:</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Minibatch</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">),</span>
                <span class="p">}</span>

                <span class="n">inference_args</span><span class="p">[</span><span class="sh">'</span><span class="s">more_replacements</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">minibatches</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="nf">_set_shared_vars</span><span class="p">({</span><span class="sh">'</span><span class="s">model_input</span><span class="sh">'</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="sh">'</span><span class="s">model_output</span><span class="sh">'</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">_inference</span><span class="p">(</span><span class="n">inference_type</span><span class="p">,</span> <span class="n">inference_args</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Predicts values of new data with a trained Linear Regression model
        Parameters
        ----------
        X : numpy array, shape [n_samples, n_features]
        return_std : Boolean flag of whether to return standard deviations with mean values. Defaults to False.
        </span><span class="sh">"""</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">PyMC3ModelsError</span><span class="p">(</span><span class="sh">'</span><span class="s">Run fit on the model before predict.</span><span class="sh">'</span><span class="p">)</span>

        <span class="n">num_samples</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">create_model</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">_set_shared_vars</span><span class="p">({</span><span class="sh">'</span><span class="s">model_input</span><span class="sh">'</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="sh">'</span><span class="s">model_output</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)})</span>

        <span class="n">self</span><span class="p">.</span><span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nf">sample_ppc</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">trace</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">cached_model</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">ppc</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">ppc</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">].</span><span class="nf">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">ppc</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Scores new data with a trained model.
        Parameters
        ----------
        X : numpy array, shape [n_samples, n_features]
        y : numpy array, shape [n_samples, ]
        </span><span class="sh">"""</span>

        <span class="k">return</span> <span class="nf">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">file_prefix</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">inference_type</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">inference_type</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">num_pred</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">num_pred</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">num_training_samples</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span>
        <span class="p">}</span>

        <span class="nf">super</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="n">file_prefix</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">file_prefix</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nf">super</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="n">file_prefix</span><span class="p">,</span> <span class="n">load_custom_params</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">inference_type</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">inference_type</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_pred</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">num_pred</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">num_training_samples</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">HorseshoeRegression</span><span class="p">(</span><span class="n">BayesianModel</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Linear Regression built using PyMC3.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">HorseshoeRegression</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ppc</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Creates and returns the PyMC3 model.
        Note: The size of the shared variables must match the size of the training data. Otherwise, setting the shared variables later will raise an error. See http://docs.pymc.io/advanced_theano.html
        Returns
        ----------
        the PyMC3 model
        </span><span class="sh">"""</span>
        <span class="n">model_input</span> <span class="o">=</span> <span class="n">theano</span><span class="p">.</span><span class="nf">shared</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_pred</span><span class="p">]))</span>

        <span class="n">model_output</span> <span class="o">=</span> <span class="n">theano</span><span class="p">.</span><span class="nf">shared</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span><span class="p">))</span>

        <span class="n">self</span><span class="p">.</span><span class="n">shared_vars</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">model_input</span><span class="sh">'</span><span class="p">:</span> <span class="n">model_input</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">model_output</span><span class="sh">'</span><span class="p">:</span> <span class="n">model_output</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Model</span><span class="p">()</span>
        <span class="n">m</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">ss</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="mi">25</span>
        <span class="k">with</span> <span class="n">model</span><span class="p">:</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">HalfNormal</span><span class="p">(</span><span class="sh">'</span><span class="s">sigma</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">tau_0</span> <span class="o">=</span> <span class="n">m</span> <span class="o">/</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">/</span> <span class="n">T</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span><span class="p">)</span>

            <span class="n">tau</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">HalfCauchy</span><span class="p">(</span><span class="sh">'</span><span class="s">tau</span><span class="sh">'</span><span class="p">,</span> <span class="n">tau_0</span><span class="p">)</span>
            <span class="n">c2</span>  <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">InverseGamma</span><span class="p">(</span><span class="sh">'</span><span class="s">c2</span><span class="sh">'</span><span class="p">,</span> <span class="n">dof</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">dof</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">ss</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">lam</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">HalfCauchy</span><span class="p">(</span><span class="sh">'</span><span class="s">lam</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">l1</span> <span class="o">=</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">T</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span>
            <span class="n">l2</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">c2</span> <span class="o">+</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">lam</span><span class="p">)</span>
            <span class="n">lam_d</span> <span class="o">=</span> <span class="n">l1</span> <span class="o">/</span> <span class="n">l2</span>

            <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="sh">'</span><span class="s">beta</span><span class="sh">'</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">lam_d</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">num_pred</span><span class="p">)</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">model_input</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">model_output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">inference_type</span><span class="o">=</span><span class="sh">'</span><span class="s">nuts</span><span class="sh">'</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">inference_args</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">draws</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1000</span><span class="p">}):</span>
        <span class="sh">"""</span><span class="s">
        Train the Linear Regression model
        Parameters
        ----------
        X : numpy array, shape [n_samples, n_features]
        y : numpy array, shape [n_samples, ]
        inference_type : string, specifies which inference method to call. Defaults to </span><span class="sh">'</span><span class="s">advi</span><span class="sh">'</span><span class="s">. Currently, only </span><span class="sh">'</span><span class="s">advi</span><span class="sh">'</span><span class="s"> and </span><span class="sh">'</span><span class="s">nuts</span><span class="sh">'</span><span class="s"> are supported
        minibatch_size : number of samples to include in each minibatch for ADVI, defaults to None, so minibatch is not run by default
        inference_args : dict, arguments to be passed to the inference methods. Check the PyMC3 docs for permissable values. If no arguments are specified, default values will be set.
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_pred</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

        <span class="n">self</span><span class="p">.</span><span class="n">inference_type</span> <span class="o">=</span> <span class="n">inference_type</span>

        <span class="k">if</span> <span class="n">y</span><span class="p">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">inference_args</span><span class="p">:</span>
            <span class="n">inference_args</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_set_default_inference_args</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">create_model</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">minibatch_size</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span><span class="p">:</span>
                <span class="n">minibatches</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">shared_vars</span><span class="p">[</span><span class="sh">'</span><span class="s">model_input</span><span class="sh">'</span><span class="p">]:</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Minibatch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">),</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">shared_vars</span><span class="p">[</span><span class="sh">'</span><span class="s">model_output</span><span class="sh">'</span><span class="p">]:</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Minibatch</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">),</span>
                <span class="p">}</span>

                <span class="n">inference_args</span><span class="p">[</span><span class="sh">'</span><span class="s">more_replacements</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">minibatches</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="nf">_set_shared_vars</span><span class="p">({</span><span class="sh">'</span><span class="s">model_input</span><span class="sh">'</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="sh">'</span><span class="s">model_output</span><span class="sh">'</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">_inference</span><span class="p">(</span><span class="n">inference_type</span><span class="p">,</span> <span class="n">inference_args</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Predicts values of new data with a trained Linear Regression model
        Parameters
        ----------
        X : numpy array, shape [n_samples, n_features]
        return_std : Boolean flag of whether to return standard deviations with mean values. Defaults to False.
        </span><span class="sh">"""</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">PyMC3ModelsError</span><span class="p">(</span><span class="sh">'</span><span class="s">Run fit on the model before predict.</span><span class="sh">'</span><span class="p">)</span>

        <span class="n">num_samples</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">cached_model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">create_model</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">_set_shared_vars</span><span class="p">({</span><span class="sh">'</span><span class="s">model_input</span><span class="sh">'</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="sh">'</span><span class="s">model_output</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)})</span>

        <span class="n">self</span><span class="p">.</span><span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nf">sample_ppc</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">trace</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">cached_model</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">selfl</span><span class="p">.</span><span class="n">ppc</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">ppc</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">].</span><span class="nf">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">ppc</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Scores new data with a trained model.
        Parameters
        ----------
        X : numpy array, shape [n_samples, n_features]
        y : numpy array, shape [n_samples, ]
        </span><span class="sh">"""</span>

        <span class="k">return</span> <span class="nf">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">file_prefix</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">inference_type</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">inference_type</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">num_pred</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">num_pred</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">num_training_samples</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span>
        <span class="p">}</span>

        <span class="nf">super</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="n">file_prefix</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">file_prefix</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nf">super</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="n">file_prefix</span><span class="p">,</span> <span class="n">load_custom_params</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">inference_type</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">inference_type</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_pred</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">num_pred</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_training_samples</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">num_training_samples</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generate some sparse data to play with
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">200</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="n">coef</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
<span class="n">inds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">inds</span><span class="p">)</span>
<span class="n">coef</span><span class="p">[</span><span class="n">inds</span><span class="p">[</span><span class="mi">10</span><span class="p">:]]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># sparsify coef
</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span>

<span class="c1"># add noise
</span><span class="n">y</span> <span class="o">+=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>

<span class="c1"># Split data in train set and test set
</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_beta</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">b_hat</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b_hat</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b_hat</span> <span class="o">+</span> <span class="n">std</span><span class="p">,</span> <span class="n">b_hat</span> <span class="o">-</span> <span class="n">std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">bernoulli</span>

    <span class="n">alpha</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">sig_p</span> <span class="o">=</span> <span class="mf">0.05</span>

    <span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">if</span> <span class="nf">bernoulli</span><span class="p">(</span><span class="n">sig_p</span><span class="p">).</span><span class="nf">rvs</span><span class="p">():</span>
            <span class="k">if</span> <span class="nf">bernoulli</span><span class="p">(</span><span class="mf">0.5</span><span class="p">).</span><span class="nf">rvs</span><span class="p">():</span>
                <span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">f</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">f</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="nf">make_data</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mpl</span><span class="p">.</span><span class="nf">rc_context</span><span class="p">():</span>
    <span class="n">mpl</span><span class="p">.</span><span class="nf">rc</span><span class="p">(</span><span class="sh">'</span><span class="s">figure</span><span class="sh">'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">navy</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">original coefficients</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="2021-03-01-bayesian-feature-selection_files/2021-03-01-bayesian-feature-selection_5_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lasso</span> <span class="o">=</span> <span class="nc">BayesianLassoRegression</span><span class="p">()</span>
<span class="n">lasso</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_pred_lasso</span> <span class="o">=</span> <span class="n">lasso</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">r2_score_lasso</span> <span class="o">=</span> <span class="n">lasso</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">lasso</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">r^2 on test data : %f</span><span class="sh">"</span> <span class="o">%</span> <span class="n">r2_score_lasso</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Multiprocess sampling (2 chains in 2 jobs)
NUTS: [sigma, beta]
Sampling 2 chains: 100%|██████████| 3000/3000 [04:20&lt;00:00, 10.81draws/s]
The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.
The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.
The estimated number of effective samples is smaller than 200 for some parameters.
100%|██████████| 2000/2000 [00:15&lt;00:00, 125.78it/s]

BayesianLassoRegression()
r^2 on test data : -0.003733
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">horse_lasso</span> <span class="o">=</span> <span class="nc">HorseshoeRegression</span><span class="p">()</span>
<span class="n">horse_lasso</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_pred_hlasso</span> <span class="o">=</span> <span class="n">horse_lasso</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">r2_score_hlasso</span> <span class="o">=</span> <span class="nf">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred_hlasso</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">r^2 on test data : %f</span><span class="sh">"</span> <span class="o">%</span> <span class="n">r2_score_hlasso</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Multiprocess sampling (2 chains in 2 jobs)
NUTS: [beta, lam, c2, tau, sigma]
Sampling 2 chains: 100%|██████████| 3000/3000 [01:37&lt;00:00, 30.67draws/s]
 47%|████▋     | 934/2000 [00:07&lt;00:08, 120.36it/s]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">mpl</span><span class="p">.</span><span class="nf">rc_context</span><span class="p">():</span>
    <span class="n">mpl</span><span class="p">.</span><span class="nf">rc</span><span class="p">(</span><span class="sh">'</span><span class="s">figure</span><span class="sh">'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">coef</span><span class="p">,</span> <span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">navy</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">original coefficients</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">lasso</span><span class="p">.</span><span class="n">trace</span><span class="p">.</span><span class="nf">get_values</span><span class="p">(</span><span class="sh">'</span><span class="s">beta</span><span class="sh">'</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">T</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">gold</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">original coefficients</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">horse_lasso</span><span class="p">.</span><span class="n">trace</span><span class="p">.</span><span class="nf">get_values</span><span class="p">(</span><span class="sh">'</span><span class="s">beta</span><span class="sh">'</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">T</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">lightgreen</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">original coefficients</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">'</span><span class="s">best</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="2021-03-01-bayesian-feature-selection_files/2021-03-01-bayesian-feature-selection_8_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pymc3</span> <span class="kn">import</span> <span class="n">summary</span><span class="p">,</span> <span class="n">traceplot</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2021/01/01/Mixed-Models.html"><h2 class="larger">Mixed Models</h2></a>
          <br><span class="smaller">January 1, 2021</span>  <br/>
          <div><p>Often, we have data which has a group structure. For example, in the dataset we use in this post, radon measurements were taken in ~900 houses in 85 counties. It’s unreasonable to expect that radon levels do not vary by state as well as house, and so we will integrate this into our analysis.</p>

<p>Typically, in linear regression we assume that each data point is independent and regresses with a constant slope amongst each other:</p>

\[y = X^T\beta + \varepsilon\]

<p>where</p>

\[\varepsilon \sim N\left(0, I\right)\]

<p>and \(X\) are known as fixed effects coefficients. To define a mixed model, we include a term \(Z\eta\), which corresponds to <em>random</em> effects. The model is now:</p>

\[y = X^T\beta + Z^T\eta + \varepsilon\]

<p>where</p>

\[\varepsilon \sim N\left(0, \sigma\right)\]

<p>and</p>

\[\eta \sim N\left(0, \sigma^2I\right)\]

<p>We wish to infer \(\beta, \eta, \sigma\). Given the random effects have mean 0, the term \(X^T\beta\) captures the data’s mean amd the term \(Z^T\eta\) captures variations in the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span><span class="p">;</span> <span class="n">sns</span><span class="p">.</span><span class="nf">set_context</span><span class="p">(</span><span class="sh">'</span><span class="s">notebook</span><span class="sh">'</span><span class="p">)</span>

<span class="kn">import</span> <span class="n">pystan</span>
<span class="kn">import</span> <span class="n">statsmodels.formula.api</span> <span class="k">as</span> <span class="n">smf</span>
<span class="kn">from</span> <span class="n">patsy</span> <span class="kn">import</span> <span class="n">dmatrices</span>

<span class="c1"># Import radon data
</span><span class="n">radon</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">radon.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">radon</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">radon</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nb">str</span><span class="p">.</span><span class="n">strip</span><span class="p">)</span>
<span class="n">radon_mn</span> <span class="o">=</span> <span class="n">radon</span><span class="p">.</span><span class="nf">assign</span><span class="p">(</span><span class="n">fips</span><span class="o">=</span><span class="n">radon</span><span class="p">.</span><span class="n">stfips</span><span class="o">*</span><span class="mi">1000</span> <span class="o">+</span> <span class="n">radon</span><span class="p">.</span><span class="n">cntyfips</span><span class="p">)[</span><span class="n">radon</span><span class="p">.</span><span class="n">state</span><span class="o">==</span><span class="sh">'</span><span class="s">MN</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">radon_mn</span><span class="p">.</span><span class="n">county</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">.</span><span class="n">county</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>
<span class="n">n_county</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">.</span><span class="n">county</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>

<span class="n">county_lookup</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">mn_counties</span><span class="p">,</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">mn_counties</span><span class="p">))))</span>
<span class="n">county</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">[</span><span class="sh">'</span><span class="s">county_code</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">.</span><span class="n">county</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="n">county_lookup</span><span class="p">).</span><span class="n">values</span>
<span class="n">radon</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">.</span><span class="n">activity</span>
<span class="n">log_radon</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">[</span><span class="sh">'</span><span class="s">log_radon</span><span class="sh">'</span><span class="p">]</span>
<span class="n">floor_measure</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">.</span><span class="n">floor</span><span class="p">.</span><span class="n">values</span>

<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">radon_mn</span><span class="p">.</span><span class="n">Uppm</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">radon_mn</span><span class="p">[</span><span class="sh">'</span><span class="s">fips</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">.</span><span class="n">stfips</span><span class="o">*</span><span class="mi">1000</span> <span class="o">+</span> <span class="n">radon_mn</span><span class="p">.</span><span class="n">cntyfips</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">radon_mn</span><span class="p">.</span><span class="n">activity</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mf">0.1</span><span class="p">)).</span><span class="nf">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1a229295c0&gt;
</code></pre></div></div>

<p><img src="2021-01-01-Mixed-Models_files/2021-01-01-Mixed-Models_4_1.png" alt="png" /></p>

<p>The simplest qway to fit a mixed model is to use StatsModels: which is what we’ll do!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">[[</span><span class="sh">'</span><span class="s">county</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">log_radon</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">floor</span><span class="sh">'</span><span class="p">]]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">formula</span> <span class="o">=</span> <span class="sh">"</span><span class="s">log_radon ~ floor + county</span><span class="sh">"</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">md</span>  <span class="o">=</span> <span class="n">smf</span><span class="p">.</span><span class="nf">mixedlm</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">county</span><span class="sh">"</span><span class="p">])</span>
<span class="n">mdf</span> <span class="o">=</span> <span class="n">md</span><span class="p">.</span><span class="nf">fit</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/thomas.kealy/anaconda3/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2066: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.
  warnings.warn(msg, ConvergenceWarning)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">mdf</span><span class="p">.</span><span class="nf">summary</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                Mixed Linear Model Regression Results
======================================================================
Model:                 MixedLM      Dependent Variable:      log_radon
No. Observations:      919          Method:                  REML     
No. Groups:            85           Scale:                   0.5279   
Min. group size:       1            Likelihood:              -994.6192
Max. group size:       116          Converged:               Yes      
Mean group size:       10.8                                           
----------------------------------------------------------------------
                            Coef.  Std.Err.   z    P&gt;|z| [0.025 0.975]
----------------------------------------------------------------------
Intercept                    0.887    0.810  1.095 0.274 -0.701  2.475
county[T.ANOKA]              0.043    1.088  0.040 0.968 -2.090  2.177
county[T.BECKER]             0.662    1.167  0.568 0.570 -1.625  2.949
county[T.BELTRAMI]           0.700    1.123  0.623 0.533 -1.501  2.901
county[T.BENTON]             0.567    1.147  0.494 0.621 -1.682  2.816
county[T.BIG STONE]          0.650    1.167  0.557 0.578 -1.637  2.936
county[T.BLUE EARTH]         1.138    1.104  1.031 0.303 -1.026  3.301
county[T.BROWN]              1.109    1.148  0.966 0.334 -1.140  3.358
county[T.CARLTON]            0.158    1.113  0.142 0.887 -2.022  2.339
county[T.CARVER]             0.679    1.128  0.602 0.547 -1.533  2.890
county[T.CASS]               0.541    1.136  0.476 0.634 -1.685  2.767
county[T.CHIPPEWA]           0.869    1.148  0.757 0.449 -1.381  3.118
county[T.CHISAGO]            0.197    1.128  0.175 0.861 -2.013  2.408
county[T.CLAY]               1.119    1.104  1.014 0.311 -1.044  3.282
county[T.CLEARWATER]         0.481    1.148  0.419 0.675 -1.768  2.730
county[T.COOK]              -0.170    1.204 -0.141 0.888 -2.529  2.189
county[T.COTTONWOOD]         0.380    1.148  0.331 0.741 -1.870  2.630
county[T.CROW WING]          0.273    1.108  0.246 0.805 -1.898  2.444
county[T.DAKOTA]             0.485    1.091  0.444 0.657 -1.654  2.623
county[T.DODGE]              0.930    1.167  0.797 0.426 -1.357  3.216
county[T.DOUGLAS]            0.863    1.115  0.774 0.439 -1.322  3.049
county[T.FARIBAULT]         -0.109    1.128 -0.096 0.923 -2.320  2.102
county[T.FILLMORE]           0.532    1.204  0.442 0.658 -1.827  2.891
county[T.FREEBORN]           1.226    1.114  1.100 0.271 -0.958  3.409
county[T.GOODHUE]            1.078    1.104  0.976 0.329 -1.087  3.242
county[T.HENNEPIN]           0.506    1.040  0.486 0.627 -1.533  2.544
county[T.HOUSTON]            0.900    1.128  0.798 0.425 -1.311  3.111
county[T.HUBBARD]            0.389    1.136  0.342 0.732 -1.838  2.616
county[T.ISANTI]             0.204    1.167  0.175 0.861 -2.083  2.490
county[T.ITASCA]             0.083    1.111  0.074 0.941 -2.095  2.260
county[T.JACKSON]            1.149    1.136  1.012 0.312 -1.077  3.375
county[T.KANABEC]            0.382    1.148  0.333 0.739 -1.868  2.631
county[T.KANDIYOHI]          1.189    1.147  1.036 0.300 -1.060  3.437
county[T.KITTSON]            0.730    1.167  0.625 0.532 -1.557  3.017
county[T.KOOCHICHING]       -0.018    1.123 -0.016 0.987 -2.218  2.182
county[T.LAC QUI PARLE]      2.064    1.204  1.714 0.086 -0.296  4.423
county[T.LAKE]              -0.401    1.115 -0.359 0.719 -2.586  1.785
county[T.LAKE OF THE WOODS]  0.989    1.148  0.862 0.389 -1.260  3.238
county[T.LE SUEUR]           0.876    1.136  0.772 0.440 -1.349  3.102
county[T.LINCOLN]            1.435    1.147  1.250 0.211 -0.814  3.684
county[T.LYON]               1.092    1.119  0.975 0.329 -1.102  3.286
county[T.MAHNOMEN]           0.499    1.309  0.381 0.703 -2.066  3.064
county[T.MARSHALL]           0.751    1.115  0.674 0.500 -1.433  2.936
county[T.MARTIN]             0.220    1.123  0.196 0.845 -1.981  2.420
county[T.MCLEOD]             0.432    1.106  0.391 0.696 -1.735  2.599
county[T.MEEKER]             0.359    1.136  0.316 0.752 -1.868  2.586
county[T.MILLE LACS]         0.081    1.204  0.067 0.946 -2.278  2.440
county[T.MORRISON]           0.294    1.115  0.263 0.792 -1.891  2.478
county[T.MOWER]              0.840    1.105  0.760 0.447 -1.327  3.006
county[T.MURRAY]             1.614    1.309  1.233 0.217 -0.951  4.179
county[T.NICOLLET]           1.291    1.148  1.125 0.261 -0.959  3.540
county[T.NOBLES]             1.055    1.167  0.905 0.366 -1.231  3.342
county[T.NORMAN]             0.398    1.166  0.341 0.733 -1.889  2.684
county[T.OLMSTED]            0.454    1.091  0.416 0.677 -1.685  2.592
county[T.OTTER TAIL]         0.752    1.119  0.672 0.501 -1.441  2.945
county[T.PENNINGTON]         0.303    1.167  0.260 0.795 -1.983  2.590
county[T.PINE]              -0.074    1.128 -0.066 0.947 -2.285  2.137
county[T.PIPESTONE]          0.991    1.147  0.863 0.388 -1.258  3.239
county[T.POLK]               0.852    1.148  0.743 0.458 -1.397  3.101
county[T.POPE]               0.420    1.204  0.349 0.727 -1.939  2.779
county[T.RAMSEY]             0.309    1.077  0.287 0.774 -1.802  2.421
county[T.REDWOOD]            1.111    1.136  0.978 0.328 -1.115  3.337
county[T.RENVILLE]           0.800    1.166  0.686 0.493 -1.486  3.086
county[T.RICE]               0.977    1.111  0.879 0.379 -1.201  3.155
county[T.ROCK]               0.448    1.204  0.372 0.710 -1.911  2.807
county[T.ROSEAU]             0.795    1.105  0.719 0.472 -1.371  2.961
county[T.SCOTT]              0.935    1.106  0.846 0.398 -1.232  3.102
county[T.SHERBURNE]          0.238    1.119  0.213 0.832 -1.956  2.431
county[T.SIBLEY]             0.388    1.148  0.338 0.736 -1.862  2.637
county[T.ST LOUIS]           0.036    0.857  0.042 0.967 -1.644  1.715
county[T.STEARNS]            0.631    1.089  0.579 0.562 -1.503  2.765
county[T.STEELE]             0.717    1.113  0.644 0.519 -1.464  2.897
county[T.STEVENS]            0.922    1.204  0.766 0.444 -1.437  3.281
county[T.SWIFT]              0.139    1.148  0.122 0.903 -2.110  2.389
county[T.TODD]               0.852    1.166  0.730 0.465 -1.434  3.138
county[T.TRAVERSE]           1.133    1.148  0.987 0.323 -1.116  3.382
county[T.WABASHA]            0.955    1.122  0.851 0.395 -1.244  3.155
county[T.WADENA]             0.434    1.136  0.382 0.702 -1.792  2.660
county[T.WASECA]            -0.181    1.147 -0.158 0.875 -2.430  2.068
county[T.WASHINGTON]         0.476    1.095  0.435 0.664 -1.670  2.622
county[T.WATONWAN]           1.813    1.167  1.553 0.120 -0.475  4.100
county[T.WILKIN]             1.353    1.309  1.034 0.301 -1.212  3.919
county[T.WINONA]             0.769    1.105  0.696 0.487 -1.397  2.935
county[T.WRIGHT]             0.779    1.106  0.705 0.481 -1.388  2.947
county[T.YELLOW MEDICINE]    0.330    1.204  0.274 0.784 -2.030  2.689
floor                       -0.689    0.071 -9.760 0.000 -0.828 -0.551
Group Var                    0.528                                    
======================================================================



/Users/thomas.kealy/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:1092: RuntimeWarning: invalid value encountered in sqrt
  bse_ = np.sqrt(np.diag(self.cov_params()))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fe_params</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">mdf</span><span class="p">.</span><span class="n">fe_params</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">LMM</span><span class="sh">'</span><span class="p">])</span>
<span class="n">random_effects</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">mdf</span><span class="p">.</span><span class="n">random_effects</span><span class="p">)</span>
<span class="n">random_effects</span> <span class="o">=</span> <span class="n">random_effects</span><span class="p">.</span><span class="nf">transpose</span><span class="p">()</span>
<span class="n">random_effects</span> <span class="o">=</span> <span class="n">random_effects</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">Group</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">LMM</span><span class="sh">'</span><span class="p">})</span>

<span class="c1">#%% Generate Design Matrix for later use
</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span>   <span class="o">=</span> <span class="nf">dmatrices</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">matrix</span><span class="sh">'</span><span class="p">)</span>
<span class="n">Terms</span>  <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">design_info</span><span class="p">.</span><span class="n">column_names</span>
<span class="n">_</span><span class="p">,</span> <span class="n">Z</span>   <span class="o">=</span> <span class="nf">dmatrices</span><span class="p">(</span><span class="sh">"</span><span class="s">log_radon ~ county</span><span class="sh">"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="sh">'</span><span class="s">matrix</span><span class="sh">'</span><span class="p">)</span>
<span class="n">X</span>      <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># fixed effect
</span><span class="n">Z</span>      <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">asarray</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="c1"># mixed effect
</span><span class="n">Y</span>      <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">asarray</span><span class="p">(</span><span class="n">Y</span><span class="p">).</span><span class="nf">flatten</span><span class="p">()</span>
<span class="n">nfixed</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">nrandm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">shape</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#%% ploting function 
</span><span class="k">def</span> <span class="nf">plotfitted</span><span class="p">(</span><span class="n">fe_params</span><span class="o">=</span><span class="n">fe_params</span><span class="p">,</span><span class="n">random_effects</span><span class="o">=</span><span class="n">random_effects</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span><span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
    <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">ax3</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">colspan</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="n">fe_params</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
    <span class="n">random_effects</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
    
    <span class="n">ax3</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">Y</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(),</span> <span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Observed</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">25</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">iname</span> <span class="ow">in</span> <span class="n">fe_params</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="nf">get_values</span><span class="p">():</span>
        <span class="n">fitted</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">fe_params</span><span class="p">[</span><span class="n">iname</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">random_effects</span><span class="p">[</span><span class="n">iname</span><span class="p">]).</span><span class="nf">flatten</span><span class="p">()</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The MSE of </span><span class="sh">"</span><span class="o">+</span> <span class="n">iname</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> is </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">Y</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()</span><span class="o">-</span><span class="n">fitted</span><span class="p">))))</span>
        <span class="n">ax3</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">fitted</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">iname</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1">#plt.ylim([0,5])
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">plotfitted</span><span class="p">(</span><span class="n">fe_params</span><span class="o">=</span><span class="n">fe_params</span><span class="p">,</span> <span class="n">random_effects</span><span class="o">=</span><span class="n">random_effects</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The MSE of LMM is 0.4784635589205236
</code></pre></div></div>

<p><img src="2021-01-01-Mixed-Models_files/2021-01-01-Mixed-Models_11_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xbar</span> <span class="o">=</span> <span class="n">radon_mn</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">county</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">floor</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">().</span><span class="nf">rename</span><span class="p">(</span><span class="n">county_lookup</span><span class="p">).</span><span class="n">values</span>
<span class="n">x_mean</span> <span class="o">=</span> <span class="n">xbar</span><span class="p">[</span><span class="n">county</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stan_code</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">
data {
  int&lt;lower=0&gt; J; 
  int&lt;lower=0&gt; N; 
  int&lt;lower=1,upper=J&gt; county[N];
  vector[N] u;
  vector[N] x;
  vector[N] x_mean;
  vector[N] y;
} 
parameters {
  vector[J] a;
  vector[3] b;
  real mu_a;
  real&lt;lower=0,upper=100&gt; sigma_a;
  real&lt;lower=0,upper=100&gt; sigma_y;
} 
transformed parameters {
  vector[N] y_hat;

  for (i in 1:N)
    y_hat[i] &lt;- a[county[i]] + u[i]*b[1] + x[i]*b[2] + x_mean[i]*b[3];
}
model {
  mu_a ~ normal(0, 1);
  a ~ normal(mu_a, sigma_a);
  b ~ normal(0, 1);
  y ~ normal(y_hat, sigma_y);
}
</span><span class="sh">"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stan_datadict</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">N</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">log_radon</span><span class="p">),</span>
                          <span class="sh">'</span><span class="s">J</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">n_county</span><span class="p">),</span>
                          <span class="sh">'</span><span class="s">county</span><span class="sh">'</span><span class="p">:</span> <span class="n">county</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># Stan counts starting at 1
</span>                          <span class="sh">'</span><span class="s">u</span><span class="sh">'</span><span class="p">:</span> <span class="n">u</span><span class="p">,</span>
                          <span class="sh">'</span><span class="s">x_mean</span><span class="sh">'</span><span class="p">:</span> <span class="n">x_mean</span><span class="p">,</span>
                          <span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">:</span> <span class="n">floor_measure</span><span class="p">,</span>
                          <span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">:</span> <span class="n">log_radon</span><span class="p">}</span>

<span class="n">stan_datadict</span><span class="p">[</span><span class="sh">'</span><span class="s">prior_only</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">sm</span> <span class="o">=</span> <span class="n">pystan</span><span class="p">.</span><span class="nc">StanModel</span><span class="p">(</span><span class="n">model_code</span><span class="o">=</span><span class="n">stan_code</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">sampling</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">stan_datadict</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_b7928e9396770558600f70afccda0012 NOW.
/Users/thomas.kealy/anaconda3/lib/python3.7/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  elif np.issubdtype(np.asarray(v).dtype, float):
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fit</span><span class="p">[</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([ 0.68677081, -0.68513895,  0.3876573 ])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">mpl</span><span class="p">.</span><span class="nf">rc_context</span><span class="p">():</span>
    <span class="n">mpl</span><span class="p">.</span><span class="nf">rc</span><span class="p">(</span><span class="sh">'</span><span class="s">figure</span><span class="sh">'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">fit</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="2021-01-01-Mixed-Models_files/2021-01-01-Mixed-Models_16_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2016/12/02/this-is-a-birthday-pony.html"><h2 class="larger">This is a birthday pony!</h2></a>
          <br><span class="smaller">December 2, 2016</span>  <br/>
          <div><p><em>This is a birthday pony</em>, for some reason, became the default placeholder text for <a href="http://stephan.druskat.net">me</a>.</p>
</div> 
        </li>
          
        <li class="listing">
          <hr class="slender">
          <a href="/tufte-css-jekyll/articles/2016/12/02/hello.html"><h2 class="larger">Hello, tufte-css-jekyll!</h2></a>
          <br><span class="smaller">December 2, 2016</span>  <br/>
          <div><p>This nothing but a simple <code class="language-plaintext highlighter-rouge">hello world</code> post.</p>

<p>In posts, you can use &lt;!–more–&gt; to control what will be shown in the excerpt.</p>

<p>For example, this post should be shown until here …</p>
</div> 
        </li>
    
  </ul>
    </article>
    <span class="print-footer">Blog - Stephan Druskat</span>
    <footer>
  <hr class="slender">
<div class="credits">
<span>&copy; 2024 
  
		<a href="mailto:mail [at] sdruskat [dot]">Stephan Druskat</a></span></br> <br>    
    

<span>Created with <a href="//jekyllrb.com">Jekyll</a> and the theme <a href="//github.com/sdruskat/tufte-css-jekyll">tufte-css-jekyll</a>.</span> 
</div>  
</footer>
  </body>
</html>
